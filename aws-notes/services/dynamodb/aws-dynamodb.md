# Amazon DynamoDB

## 概要

### 基本定義
AWS のマネージド型 NoSQL（キー・バリュー/ドキュメント）データベース

### 主な用途
- セッション/プロフィール管理
- ショッピングカート
- イベントログ
- IoT データ
- ゲームランキング

### 特徴
- サーバーレス/自動スケール
- 高スループット・低レイテンシ
- 強い耐障害性
- **デフォルトでマルチ AZ 構成**

## ストレージクラス

| クラス | 適用場面 | 特徴 |
|--------|----------|------|
| **Standard** | 頻繁アクセス | 標準クラス、まずはこれを選択 |
| **Standard-IA** | 低頻度アクセス | ストレージ単価安、アクセス単価高（アクセス多いと割高） |

## キャパシティモード

### 1. オンデマンド（On-Demand Capacity Mode）
- **予約不要**（事前設定なし）
- リクエストが来た分だけ自動で処理能力をスケール
- **課金**: 「実際に処理したリクエスト数」に基づく（従量課金）
- **適用場面**: トラフィックが予測できない場合や、新規サービス向け
- **注意**: On-Demand モードでは Auto Scaling は不要＆使えない

### 2. プロビジョンド（Provisioned Capacity Mode）
- キャパシティを事前に割り当てる（RCU / WCU を指定）
- **課金**: 「設定したキャパシティ」に基づく（使わなくても支払いが発生）
- Auto Scaling Policy（AS ポリシー）を設定すれば、アクセス量に応じて自動調整できる
- **コスト特性**: スパイクに強いのはオンデマンド、長期安定はプロビジョンドが安い傾向

### 3. リザーブドキャパシティ（Reserved Capacity）
- **プロビジョンドモード専用の割引制度**
- 1年 or 3年の契約をする代わりに、プロビジョンドの料金が割引になる
- EC2 のリザーブドインスタンス（RI）に近い考え方
- 前払いあり／なしのプランを選べる

> **重要**: 「リザーブドキャパシティ」はキャパシティモードそのものではなく、プロビジョンドモードの割引オプション

## インデックス（LSI/GSI）

### インデックスとは
DynamoDB は基本「パーティションキー（＋ソートキー）」でしか検索できない

実際のアプリでは「別の属性で検索したい」ケースが多い

→ そこで「インデックス」を作って別の検索パターンを実現できる

### GSI（Global Secondary Index）
テーブルのパーティションキー・ソートキーとは異なる属性を使って検索できるインデックス

**「Global」の意味**: 元のテーブルのパーティションキーと無関係に検索できる

#### 設定例
```
元テーブル: UserID（PK）, OrderID（SK）
GSI: Email をキーにするインデックスを作成
→ 「メールアドレスからユーザーを検索」が可能になる
```

## Streams（変更イベント）

### DynamoDB Streams
- **機能**: テーブルに対する「項目の変更ログ」
- **使いどころ**: Lambda/Kinesis でイベント駆動、監査、非同期処理
- **設定/上限**: 保持 24 時間、NEW/OLD 画像の選択
- **制約**: EventBridge には直接送れない（Lambda/Kinesis が必要）

### DynamoDB イベント通知（EventBridge 連携）
- **機能**: 最近追加された機能で、テーブル更新イベントを直接 EventBridge に発行できる
- **制約**: Streams と比べると、保持・詳細情報は限定的

### 重要ポイント
- **DynamoDB Streams** は変更ログを保持するだけの仕組み
- 「誰かに通知する」機能は持っていない
- Streams をトリガーにして起動できるのは **Lambda** or **Kinesis** のみ

### 変更イベントの取得

**PutItem / UpdateItem / DeleteItem** が発生すると、ストリームに「レコード」が流れる

#### レコードに含まれる情報
- **変更前のデータ (Old Image)**
- **変更後のデータ (New Image)**  
- **操作タイプ**（INSERT / MODIFY / REMOVE）

### 他サービスへの通知・連携

DynamoDB Streams 単体では通知を直接送らず、イベントソースとして他サービスが購読する

#### 連携可能なサービス
- **AWS Lambda**: Streams をトリガーにしてリアルタイム処理
  - 例：テーブル更新があったら別のテーブルに反映、S3にログ保存
- **Amazon Kinesis Data Streams**: より複雑なストリーム処理や外部システム連携
- **Amazon OpenSearch Service**: データ更新を検索インデックスに即時反映

### 典型的なユースケース
- **監査ログ**: 誰がいつどのデータを更新したかを保存
- **非同期処理**: 注文データが入ったら在庫を更新、通知メール送信など
- **複数テーブル同期**: Userテーブルの更新をProfileテーブルに即反映
- **イベント駆動アーキテクチャ**: DynamoDBの変更をトリガーに他のAWSサービスを動かす

## その他の主要機能

### TTL（Time to Live）
- **使いどころ**: セッション/キャッシュの自動削除
- **注意**: 削除はベストエフォートで遅延あり

### バックアップと復元
- **使いどころ**: オンデマンドバックアップ、PITR（~35日）で誤操作/DR 対応

### 暗号化
- **デフォルト**: 既定で有効
- **設定**: KMS（管理キー/顧客管理キー）を選択可能

### グローバルテーブル
- **使いどころ**: マルチリージョン配信/DR、アクティブ-アクティブ複製
- **注意**: 競合解決/整合モデルの理解が必要

## DAX（DynamoDB Accelerator）

### 概要
**Amazon DAX = DynamoDB 専用のインメモリキャッシュサービス**

DynamoDB にフルマネージドでくっつけられるキャッシュ層

### 特徴
- 読み取り処理を**ミリ秒ではなくマイクロ秒レベル**に高速化
- Redis や Memcached のように自分でキャッシュを構築する代わりに、DAX をそのまま使える
- 読み取り性能を**数百万リクエスト/秒レベル**で処理可能
- レイテンシは**マイクロ秒単位**に短縮

### 適用場面
- 「DynamoDB で読み取りをさらに高速化したい」 → DAX
- 「DynamoDB のキャッシュをアプリ側で自前構築する代わりに」 → DAX を使う
- **「読み取りが圧倒的に多い」ワークロードで威力を発揮**

### 注意点
- **書き込みではなく読み取り**が重要
- SDK/一貫性の前提を確認

## トランザクション

### 概要
通常の DynamoDB は「1つの PutItem や UpdateItem ごとに一貫性が保証」される

アプリによっては「複数アイテムをまとめて一括で成功させたい（全部成功 or 全部失敗）」という要求がある

→ これを実現するのが **DynamoDB Transactions**

### ACID 特性
- **Atomic**（一括で成功 or 失敗）
- **Consistent**（一貫性保持）
- **Isolated**（分離性あり）
- **Durable**（永続性あり）

### 機能
- 複数アイテムをまとめて操作できる
- **最大 25 アイテム / 合計 4MB まで**
- 1つのトランザクション内で Put, Update, Delete, ConditionCheck が可能

### API
- **TransactWriteItems**（書き込み系をまとめる）
- **TransactGetItems**（読み取り系をまとめる）

### 特徴・制約
- **一貫性**: 強い整合性を保証（トランザクションが完了したら全体が確定する）
- **コスト**: 高め（通常の2倍くらいのリソース消費と課金）
- **レイテンシ**: 増える（単純な PutItem/UpdateItem より遅い）
- **上限**: 25件/4MB まで

### できること（具体例）

#### 複数テーブル・複数項目をまとめて操作
- **1回のトランザクションで最大25件の操作**をまとめられる
- **複数のテーブルにまたがってもOK**
- **例**: ユーザー情報テーブル更新 ＋ 監査ログテーブルに書き込み

#### 条件付き更新（ConditionCheck）
- **「もしこの項目のステータスが ACTIVE なら更新する」**といった条件付き操作が可能
- 条件が満たされなければ、**トランザクション全体がロールバック**される

#### 機密データの安全な削除
- 個人情報や重要データを削除する処理を「関連するログ更新・監査記録」とセットでまとめられる
- 途中で失敗したら**削除だけ行われてログが残らない**みたいな不整合を防げる

#### 整合性のある業務ワークフロー
- **金融システム**: 送金元から引き落とし ＋ 送金先へ入金
- **ECサイト**: 在庫更新 ＋ 注文履歴登録
- **セッション管理**: ユーザーステータス更新 ＋ 認証トークン無効化

### 削除と書き込みの組み合わせ

DynamoDBの**トランザクション (TransactWriteItems)** を使えば、**「もし特定の条件に一致する個人情報が存在したら削除してから、新しいデータを書き込む」**という処理を**1つのトランザクション**としてまとめられる

#### 実装方法
1. **DeleteItem（削除）** と **PutItem / UpdateItem（書き込み）** を同じトランザクション内に定義
2. さらに必要なら **ConditionCheck** を入れて「この条件を満たすときだけ削除・書き込みを実行」と制御可能
3. どれか1つでも失敗したら、**全体がロールバック**されるので不整合は発生しない

> **Point**: 削除＋書き込みをトランザクションでまとめて実行することで、「個人情報があったら必ず削除してから新しいデータを入れる」という処理を**1つの原子的なオペレーション**として実現

### まとめ
- 「DynamoDB で複数アイテムを ACID 特性で更新したい」 → TransactWriteItems
- 「最大件数は？」 → **25件 / 4MB**
- **DynamoDB トランザクション** = 複数アイテムの操作を「全部成功 or 全部失敗」でまとめる仕組み
## 課金体系

### リクエスト/キャパシティ
- **オンデマンド**（アクセス課金）
- **プロビジョンド**（RCU/WCU 指定 + AS）

### ストレージ
- **Standard** / **Standard-IA**

### 付随機能
- Streams 読取
- バックアップ/PITR
- DAX クラスター
- グローバルテーブルの複製/転送
- KMS API など

## よく組み合わせる AWS サービス

| サービス | 用途 |
|----------|------|
| **AWS Lambda** | Streams でイベント駆動処理 |
| **Amazon Kinesis** | データ取り込み/ストリーム連携 |
| **Amazon S3** | バックアップ/エクスポートや ETL の中継 |
| **Amazon API Gateway/AppSync** | サーバーレス API バックエンド |
| **Amazon CloudWatch** | メトリクス/ログ監視、アラーム |

## 設計のポイント

### 設計の勘所
- アクセスパターン駆動設計
- ホットパーティション回避
- 単一テーブル設計の段階導入
- 強/最終的整合の使い分け

### よくある落とし穴
- Scan 多用でコスト/レイテンシ増
- 1MB 応答上限とページング未実装
- キー偏りによるスロットリング

---

## Streams詳細

### キャプチャ対象
- テーブルのアイテムレベルの変更履歴（挿入・更新・削除）をキャプチャ
- **検知するのは「スキーマ変更」ではなく「データ変更」**
- スキーマ変更（テーブルの属性追加・削除）は DynamoDB Streams では取れない
- キャプチャできるのはアイテム単位の変更（Insert / Update / Delete）

### 保持期間
- DynamoDB Streams のデータは**最大 7 日間保持**

### 利用方法
- Streams は **Lambda トリガー** としても使える
- **Kinesis Client Library (KCL)** を使って独自処理することも可能

### ストリームレコード内容
ストリームレコードには「NewImage」「OldImage」などが含まれ、アイテムの更新前後の状態を参照できる

#### ストリームに出てくる内容
- **KeysOnly** → 変更されたアイテムのキーだけ
- **NewImage** → 更新後のアイテム全体
- **OldImage** → 更新前のアイテム全体
- **NewAndOldImages** → 両方

### 連携先とイベント駆動

#### Lambda
- DynamoDB Streams をイベントソースに設定可能
- 例：「新しい注文が入ったら Lambda を起動して在庫を減らす」

#### Kinesis Data Streams (KCL)
- 高スループットやカスタム処理したいときに利用
- 例：「変更データを別リージョンにリアルタイムで複製」

## DAXクラスタの構成

### プライマリノード（1つ必須）
- 書き込みリクエストを処理
- データの整合性を担保

### リードレプリカノード（0〜9個）
- 読み取りリクエストを処理
- 読み取りスケーリングを実現

**DAXクラスタ = 1プライマリ + 最大9リードレプリカ = 最大10ノード で構成可能**

### フェイルオーバー
プライマリノードが障害を起こした場合:
- 自動的にリードレプリカの1つがプライマリに昇格
- アプリ側はクラスターエンドポイントに接続するため、個別のノードを意識する必要なし

### まとめ
- **DAXクラスタ構成**: 1プライマリ + 0〜9リードレプリカ
- **最大10ノードまで**
- **自動フェイルオーバー & 読み取り負荷分散**が可能
- アプリはDAXクラスタのエンドポイントに接続するだけで利用できる