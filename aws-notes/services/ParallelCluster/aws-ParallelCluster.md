# AWS ParallelCluster

## 概要
HPC（High Performance Computing：高性能計算）用のクラスタ環境を簡単に構築・管理するオープンソースのAWS公式ツール

**「スパコン的な環境をAWS上でワンクリックで作れる仕組み」**

## 特徴

### HPC クラスタの自動構築
- 計算ノード（EC2）、ジョブスケジューラ（Slurm, Torque, SGE など）、ネットワークをまとめてデプロイ
- 数ノード〜数千ノードまでスケール可能

### スケーリング
- ジョブキューに応じて自動的にノードを起動・停止
- コスト効率よくスパコン環境を利用可能

### ストレージ統合
- Amazon FSx for Lustre, Amazon EFS, Amazon S3 などを統合して高速I/Oを実現

### 再現性のある環境
- YAML形式の設定ファイルでクラスタを定義
- 同じ設定ファイルを使えば誰でも同じ環境を構築可能

### オープンソース & 無料
- ParallelCluster 自体は無料（EC2, EBS, FSx などの利用料は発生）

## ユースケース
- 科学技術計算（気象シミュレーション、分子動力学、流体力学）
- 金融リスク分析
- ゲノム解析
- 映画・アニメーションのレンダリング
- 機械学習の大規模分散学習

## まとめ
AWS ParallelCluster = HPC クラスタを簡単に構築・管理できるAWS公式ツール

自動スケーリング、ジョブスケジューラ統合、FSx/EFS/S3連携 が特長

研究・金融・メディアなど「スパコン的処理」が必要な分野で活躍

---

# Elastic Fabric Adapter (EFA)

## 概要
EC2インスタンスにアタッチできるネットワークインターフェースで、HPC や機械学習の分散トレーニングのために低レイテンシ・高スループット通信を実現する

**「AWSでMPIとか分散学習を爆速にする専用NIC」**

## 特徴

### 低レイテンシ & 高帯域幅
- 通常のEC2ネットワークよりも大幅に低遅延で通信できる

### OSバイパス通信 (OS-bypass)
- アプリケーションがOSカーネルを通さずにネットワーク通信できる
- その結果、レイテンシ削減・スループット向上

### MPI 対応
- HPCの代表的な通信ライブラリ MPI (Message Passing Interface) を利用可能
- 並列計算のノード間通信を効率化

### NCCL, Horovod などの ML フレームワーク対応
- GPU分散学習（TensorFlow, PyTorch）で活用できる

### 利用可能なEC2
- HPC系（例: C5n, P4d, P5, Hpc6a など）でサポート
- アプリは libfabric API を通じてEFAを利用

## ユースケース
- HPCシミュレーション（流体力学、気象、分子動力学）
- 機械学習の分散トレーニング（特に大規模GPUクラスター）
- 金融リスクモデリング
- 石油・ガスの地震探査シミュレーション