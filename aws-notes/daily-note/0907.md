# Route 53 とマルチリージョン構成

## Route 53 ホストゾーン

AWS Route 53で**ドメイン名の管理単位**を「**ホストゾーン**」と呼ぶ

**例**: example.com というドメインを管理するために**ホストゾーン**を作成

### パブリックホストゾーン

**インターネットからアクセス可能なDNS名前解決を提供するゾーン**

- ドメインを Route 53 で管理し、公開用の**ネームサーバー（NSレコード）**が割り当てられる
- 利用者のブラウザやスマホが「www.example.com」にアクセス可能

## Route 53 ヘルスチェック

### 概要
**Route 53のヘルスチェックは上位の仕組みで、ALBのエンドポイント（DNS名）やIPに対して定期的にHTTP/HTTPS/TCPリクエストを送って監視**

**東京リージョンのALBが死んだら、「東京側のDNSレコードを無効化して、大阪リージョンに切り替える」動作**

### ヘルスチェックの階層

#### ALBのヘルスチェック
**EC2（ターゲット）が落ちたかどうかを見て、ALB内部でトラフィックをさばく**

#### Route 53のヘルスチェック
**ALB自体が応答しているかを見て、応答がなければDNSを切り替える（東京 → 大阪）**

### Route 53 ヘルスチェックの動作

#### 監視処理
1. **Route 53がヘルスチェックを実行**
2. **東京リージョンのALBに対してHTTP/HTTPS/TCPリクエストを送る**
3. **応答があれば「正常」、なければ「異常」と判断**

#### フェイルオーバールーティングの動作
- **東京ALBが「正常」なら** → 東京にトラフィックを流す
- **東京ALBが「異常」なら** → 大阪ALB（セカンダリ）にトラフィックを切り替える

#### クライアントから見ると
- **常に www.example.com にアクセスしているだけ**
- **でもRoute 53が裏側で「どっちのALBを返すか」を自動制御**している

## データベース

**MySQLのストレージエンジンとしてInnoDBを利用**

## マルチリージョン構成のまとめ（東京 & 大阪）

### 1. アクティブ–パッシブ構成

#### 仕組み
- **Route 53のヘルスチェック + フェイルオーバールーティング**を利用
- **プライマリ（東京ALB）が落ちたら、セカンダリ（大阪ALB）に切り替わる**

#### 特徴
- **平常時は東京だけが稼働**
- **障害発生時は大阪に切替**
- **復旧すれば東京に戻すことも可能**

#### メリット・デメリット
- **メリット**: シンプル、コストが低い
- **デメリット**: パッシブ側が普段ほぼ使われない

### 2. アクティブ–アクティブ構成

#### 仕組み
- **Route 53のレイテンシーベースルーティング または 加重ルーティング**を利用
- **どちらのリージョンにもトラフィックを流す**

#### レイテンシーベース
- **ユーザーに近いリージョンにルーティング**
- **利用者体験（低遅延）を重視**

#### 加重（Weighted）
- **指定した比率（例：50:50、80:20）で分散**
- **負荷コントロールや段階的移行に便利**

### 共通の動き
**片方のリージョンが落ちると** → **Route 53ヘルスチェックにより、残ったリージョンに全トラフィック集中**

## まとめ

| 構成 | 実現方法 |
|------|----------|
| **アクティブ–パッシブ** | Route 53の「ヘルスチェック + フェイルオーバールーティング」 |
| **アクティブ–アクティブ** | Route 53の「レイテンシーベース」または「加重ルーティング」 |

> **重要**: どちらの方式でも、片方が落ちたら**残ったリージョンに全てのトラフィックが流れる**

## ステートフル vs ステートレス

### ステートフル処理用インスタンスの問題点

#### 依存性の問題
- **接続やセッション情報をサーバーに保持**するため、そのインスタンスに依存する（＝スケールしにくい）
- **サーバーが落ちればセッションが失われる**

#### リソース効率の問題
- **クライアント接続がアクティブな限りDBも使い続ける**ので、DBに不要な負荷を与える
- **分散処理には不向き**

> **結果**: これでは「AWSで求められる弾力性・スケーラビリティ」に合わない

### ステートレス処理用インスタンスのメリット

#### 状態の外部化
**状態をサーバー内に保持しない**（セッションはElastiCache、ファイルはS3、永続データはDBへ）

#### 可用性の向上
- **どのインスタンスにリクエストが行っても同じ結果を返せる**
- **Auto Scalingでのスケールアウト/インが容易**
- **障害が起きても他のインスタンスがすぐ代替できる**

#### 結果
**分散アプリケーションの性能と可用性が向上**

### 結論

**要件が「スケーラブルで弾力性のある分散処理」なら、ステートレスなEC2インスタンスを選択するのが正解**

**ステートフルなインスタンスを選ぶと、AWS移行の目的（スケーラビリティ・耐障害性）が満たせなくなる**

## ステートフルなEC2の問題（スケールアウト/イン時）

### スケールアウト時の問題
- **新しく増えたインスタンスは「前のインスタンスが持っていたセッションや状態」を知らない**
- **結果、ユーザーが別のインスタンスに割り振られると「ログインが切れる」「処理が中断される」などが起きる**

### スケールイン時の問題
- **台数が減らされると、消されたインスタンスのメモリやローカルに保持していたデータが完全に消える**
- **ユーザーがそのインスタンスに依存していた場合、データが失われる**

> **つまり**: スケールイン/アウトに伴って「状態」が揮発するのがステートフルの最大の弱点

## ステートレス設計の解決策

### 状態の外部化
- **セッション情報** → ElastiCache (Redis/Memcached)
- **ファイル** → S3
- **永続データ** → Aurora / DynamoDB

**EC2が消えても何も失われない。だからこそスケールイン/アウトが安全にできる**

ステートフルなEC2 → スケールイン/アウト時に「保持していたデータ」が消えるリスクがある

ステートレスなEC2 → 状態を外部に逃がしているので、いつ消えても問題なし

インスタンスは「いつでも増える・減る・消える」前提なので、状態を持たせると不整合が起きる

## ステートレス設計の利点

### 高可用性
**ステートレスなら、インスタンス1台が落ちても他のサーバーで即代替可能**

**これにより可用性が高い分散システムを作れる**

### CDNやキャッシュとの相性
**CloudFront, S3, ElastiCache, DynamoDB, Aurora などと組み合わせると、EC2/Fargate/ECS は「処理するだけのワーカー」になれる**

> **これがいわゆる「マイクロサービス」「サーバーレス」の基盤思想**

## モダンなアプリの実装パターン

### アーキテクチャ構成
- **Web層（API, フロントエンド）** → ステートレス (ECS, EKS, Lambda, EC2)
- **セッション管理** → ElastiCache (Redis)
- **ファイル** → Amazon S3
- **DB** → Aurora / DynamoDB
- **グローバル配信** → CloudFront

> **ベストプラクティス**: これらを組み合わせて「**ステートレスなアプリケーション層 + ステートフルなマネージドサービス層**」に分離するのが今の標準

EC2の詳細モニタリングは１分ごとにログだせる

C2 の詳細モニタリングとは

EC2 インスタンスのメトリクスを Amazon CloudWatch に送信する仕組みで、標準モニタリングと比較して メトリクスの粒度が細かい のが特徴です。

標準モニタリング (Basic Monitoring)

5分間隔でメトリクス送信

無料

詳細モニタリング (Detailed Monitoring)

1分間隔でメトリクス送信

有料（追加課金あり）

取得できるメトリクスの種類自体は同じですが、解像度が違う

ユースケース
1. オートスケーリングの精度向上

Auto Scaling Group が CloudWatch メトリクスをトリガーにスケールする場合、1分単位で反応できる

高トラフィックに素早く対応したい場合に有効

2. より精細な可観測性が必要なとき

短時間で急増する負荷やスパイクを検知したい

5分粒度だと見逃すような「瞬間的なCPU急上昇」などをキャッチ可能

3. SLA / 運用要件で細かい監視が必要な場合

金融システムやゲームなど、瞬間的な負荷に弱いサービス

運用チームが「1分以内に異常検知」したいケース

ユースケース = より早いスケーリング / 短期的な負荷検知 / 厳しい監視要件

1. 出るログの「種類」は変わらない

標準モニタリング（5分間隔） と 詳細モニタリング（1分間隔） で取れるメトリクス項目は同じです。

例: CPUUtilization, NetworkIn, DiskReadOps など

なので「ログのレベルや種類が増える」わけではありません。

2. 違うのは「送信頻度（解像度）」

標準: 5分おき

詳細: 1分おき
→ より「こまかく」監視できるようになるだけ。

3. 使いどころ

スパイクが短時間で発生するようなワークロード

オートスケーリングの精度を上げたいとき

SLAや運用ポリシーで細かい監視が求められるとき

## DataPipeline（現状）
サービス終了

## EBS io2 Block Express
256,000 IOPSを達成できる非常に高性能なボリューム

## PV AMI (Paravirtual AMI)
- 「ハードウェアを直接叩かず、ハイパーバイザーにお願いして動くタイプの仮想化」
- 非推奨（新規作成不可）
- 昔のEC2で使われていた仮想化方式のAMI（今はHVMが主流）

## 認証サービス

### Identity Center
- フェデレーションはIdPだけでなくADも可能

### AWS Organizations
- 複数のAWSアカウントを統合的に管理するための仕組み
- 認証を行うための機能は備えていない

### AWS Cognito
- ウェブアプリケーションやモバイルアプリケーションにおける認証、許可、ユーザー管理を実現するサービス

### IAMグループ
- IAMユーザーをまとめて権限を設定するためのグループ
- Active Directoryによる認証を利用できない

---

## CloudWatch エージェント

### 動作する場所

#### 1. Amazon EC2
- 一番よく使われるケース
- OSレベルのメトリクス（CPU、メモリ、ディスクI/O、ネットワーク帯域など）やログを CloudWatch に送信

#### 2. オンプレミスサーバー
- ハイブリッド環境でも利用可能
- Systems Manager (SSM) を使ってオンプレLinux/Windowsにインストールして監視対象にできる

#### 3. その他AWSサービス
- Amazon ECS / EKS のコンテナ上でも利用可能
- CloudWatch Container Insights と組み合わせて、タスクやPod単位のメトリクスを収集できる

### CloudWatch エージェントの対象
- 主にOSレベルのリソース監視
- CPU、メモリ、ディスク、ネットワーク など
- OSログ（/var/log/messages, Windows Event Logなど）

**「インスタンス（EC2やオンプレサーバー）」にインストールして動かすもの**

**CloudWatch エージェント = サーバーやコンテナの中からメトリクス・ログを送るためのもの**

### RDSの場合
RDSは マネージドサービス なので、EC2みたいに中にエージェントを入れることはできない

代わりに、AWS側で以下を自動的に提供：
- **CloudWatch 標準メトリクス**（CPU使用率、FreeStorage、DB接続数など）
- **Enhanced Monitoring**（OSレベルの詳細メトリクス、実質的にRDS内部の専用エージェントがAWS管理下で動いている）
- **Performance Insights**（SQLレベルのパフォーマンス分析）

### 補足
拡張モニタリング（Enhanced Monitoring）と Performance Insights は別物。前者はOS視点、後者はSQL視点。

## Lambda コールドスタート対策
lambdaコールドスタート問題が気になるなら プロビジョンド同時実行 (Provisioned Concurrency) を設定

## API Gateway
- 完全マネージドでリクエスト数に応じて自動スケール
- 特別な設定は不要
- 急増に備えるなら スロットリング制御 を設定してバックエンドを守る

## CloudFront 署名付きCookies vs 署名付きURL

### 署名付きCookies
- 現在のオブジェクトURLを変更せずに、有料会員のみに複数のプライベート動画ファイルへのアクセスを提供

### 署名付きURL
- 改めて動画コンテンツに対して署名付きURLを付与することになるため、現在のオブジェクトURLが変更されてしまう

## Auto Scaling
Auto ScalingグループにALBのターゲットグループを構成して、EC2インスタンスを複数のアベイラビリティゾーンに分散

---

## SQSベースのAuto Scaling

### 概要
SQSキューに溜まったメッセージ数をトリガーにして、EC2のAuto Scalingを制御する仕組み

Webアプリなどで「リクエストを一旦 SQS に貯めて、EC2ワーカーで処理する」構成がよくある
- キューが空ならEC2台数を減らす
- キューに大量に溜まったらEC2を増やす

これを自動化するのが「ターゲット追跡スケーリングポリシー + ApproximateNumberOfMessages」

### ApproximateNumberOfMessages とは
SQSのメトリクスで、キュー内に「まだ処理されていないメッセージ数」を表す

**例**: ApproximateNumberOfMessages = 100 → 未処理メッセージが100件ある

### ターゲット追跡スケーリングポリシー
Auto Scaling のスケーリングポリシーの一種

「このメトリクスをこの値に保つように台数を調整する」という方式

**例**: ターゲット値を 10 に設定
- 意味：「EC2インスタンス1台あたり平均して10メッセージくらいで回せるように、インスタンス数を調整する」

### 動作イメージ
1. SQS にメッセージが急に溜まる（例: 1000件）
2. ApproximateNumberOfMessages の値がターゲット値を大きく超える
3. Auto Scaling グループが EC2 を増やす（スケールアウト）
4. EC2 が処理を進める → キューが減る
5. メッセージ数がターゲット値を下回る → スケールイン

### メリット
- 手動で「CPUが80%になったら増やす」とか考えなくて良い
- キューの長さに応じて自動で台数調整できる
- バックエンドのワーカー処理に最適