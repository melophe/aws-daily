# AWS 学習メモ 0916

## SQS と SNS の違い

### SQS
- メッセージを受け取る「キュー」にアクセスポリシー
- 誰が SendMessage できるか制御

### SNS
- メッセージを受け取る「トピック」にアクセスポリシー
- 誰が Publish できるか、誰が Subscribe できるか制御

> EventBridge はつけない

---

## CloudFormation の Egress の意味

- Egress: true → アウトバウンドルール（送信）
- Egress: false → インバウンドルール（受信）

---

## RTMP

- RTMP = Real-Time Messaging Protocol
- アドビ（旧マクロメディア）が開発した、音声・動画・データをリアルタイムで配信するための通信プロトコル

---

## Amazon IVS とは

- フルマネージドの 低遅延ライブ配信サービス
- Twitch の技術をベースに構築されている
- 数行のコードでライブ配信機能をアプリやWebに組み込める

### Amazon IVS vs AWS Elemental

#### Amazon IVS
- ライブ配信に特化、超低遅延
- 開発者向けに「配信機能をアプリに組み込む」用途

#### AWS Elemental MediaLive / MediaPackage
- 本格的な映像配信プラットフォーム構築向け
- 大規模放送局・OTTサービスで利用される

---

## CloudWatch メトリクス収集

### EC2 の場合

#### 標準メトリクス
- EC2 インスタンスを起動すると、CloudWatch に自動で 基本的なメトリクス（CPU使用率、ディスク、ネットワーク） が送信される

#### CloudWatch Agent
- メモリ使用率やプロセス情報など、標準で取れない追加メトリクスを収集したいときに CloudWatch Agent をインストールして使う

### コンテナ（EKS / ECS / Fargate）の場合

- コンテナは「EC2 みたいにインスタンス単位」ではなく、「Pod / Task / Service 単位」で監視したい
- でも標準では コンテナごとの CPU やメモリ使用率 は CloudWatch に送信されない
- そこで登場するのが CloudWatch Container Insights

#### Container Insights を有効化すると
- EKS / ECS / Fargate の クラスタ・ノード・Pod・コンテナごとのメトリクス を自動収集
- Kubernetes のメトリクス（kubelet / cAdvisor 由来）や Fluent Bit 経由のログも CloudWatch に統合
- CloudWatch Agent をコンテナ環境に最適化した拡張機能 みたいなイメージ

---

## CloudWatch Container Insights vs AWS X-Ray

### CloudWatch Container Insights

#### どこを見る？
- インフラ／コンテナリソースの利用状況（CPU、メモリ、ネットワーク、ディスク）

#### 対象
- クラスター（EKS/ECS）、ノード（EC2）、Pod、コンテナ、サービス

#### 得意なこと
- 「どの Pod がメモリを食いすぎてるか？」
- 「どのノードが CPU ボトルネックになってるか？」
- 「クラスタ全体のリソースが逼迫していないか？」

#### 用途
- インフラ／コンテナレベルの 運用監視・キャパシティ計画

### AWS X-Ray

#### どこを見る？
- アプリケーションコードのリクエスト経路（分散トレーシング）

#### 対象
- マイクロサービス間のリクエストフロー（API Gateway → EKS → DB など）

#### 得意なこと
- 「このリクエストはどのサービスを経由したか？」
- 「どのマイクロサービスで遅延やエラーが発生しているか？」
- 「外部サービス呼び出し（DB、S3、API）のレスポンス時間は？」

#### 用途
- アプリケーションの 性能分析・ボトルネック調査

---

## Site-to-Site VPN の比較

### AWS Site-to-Site VPN（通常版）
- オンプレミス（データセンターやオフィスのルーター）と AWS VPC を接続する仕組み
- 公開インターネットを経由して IPSec VPN トンネル を張る
- 通常は インターネット経由のため遅延やジッターが発生しやすい

### Accelerated Site-to-Site VPN
- AWS Global Accelerator のネットワークを利用して、オンプレと AWS の間の VPN 通信を AWS グローバルバックボーンネットワーク に流せる機能
- インターネットを長距離利用せず、AWS の専用ネットワークで中継することで 低レイテンシ・安定した通信 が可能

### まとめ
- Accelerated Site-to-Site VPN = Global Accelerator を活用した高速・低遅延の VPN 接続
- 「Site-to-Site VPN + Global Accelerator」＝ Accelerated Site-to-Site VPN
- Site-to-Site VPN → IPSec トンネルでの接続方式
- Global Accelerator → AWS グローバルネットワークでの最適経路選択

---

## Amazon Data Lifecycle Manager

- Amazon EBS ボリュームに保存されたデータをバックアップする自動化された手順
- ライフサイクルポリシーを作成し、スナップショット管理を自動化

Customer Gateway
オンプレミス環境とAWS VPCをVPNで接続する際にオンプレ側に設定する仮想ルーターのこと

オンプレ側を表現する「論理的なリソース」

AWS Global Accelerator

AWS グローバルネットワークを使って、世界中から ALB/NLB/EC2 へのアクセスを最適化

エニーキャスト IP による最短経路ルーティング & 可用性向上

直接構成できるのは ALB または NLB

ただし推奨されるのは NLBとの統合（レイヤー的に自然かつ高速）

ALB + Global Accelerator

Web アプリ（HTTP/HTTPS、パスベース/ホストベースルーティング）が必要なら ALBが第一選択。

Global Accelerator を使うと、

グローバルなクライアントから ALB までの ネットワーク経路を最適化

ALB のリスナールール（L7ルーティング）はそのまま活かせる

「世界中からアクセスされる Web サイト/アプリ」ならこちらが推奨。

 NLB + Global Accelerator

L4 トラフィック（TCP/UDP）、超低レイテンシが求められる場合はこちら。

例: 金融取引、ゲームサーバー、VoIP、IoT など

数百万リクエスト/秒の処理能力が必要なときに最適。

DLM (Data Lifecycle Manager) は、EBSスナップショットやEBS-backed AMIを自動で作成・削除するためのサービス

EBSの定期バックアップ

災害復旧 (DR) 対応

AMI管理

AWS Instance Scheduler

EventBridge、Lambda、DynamoDB を組み合わせて、EC2 と RDS のスケジュール起動/停止を自動化

EC2 と RDS の両方に対応

インスタンスにタグを付けるだけで制御対象にできる

複数アカウントや複数リージョンもサポート

運用管理をほぼ不要にできる

cron方式 = 「スケジューラ専用の EC2 サーバーを常時稼働」させないといけない
→ インスタンス代が発生し、管理も必要

Lambda + EventBridge 方式 = 「AWSのマネージドなスケジューラ（EventBridge）が Lambda を呼び出す」
→ サーバーレスなので余計なEC2が不要

Amazon Managed Service for Apache Flink = フルマネージドな Apache Flink 環境
→ ストリーミングデータを リアルタイムに処理・分析 できるサービス。
適している処理
1. リアルタイム集計

例:

株式取引の売買データを秒単位で集計

Webサイトのクリック数を即時にカウント

Flink の「ウィンドウ処理（tumbling, sliding, session window）」を使って、時間ごとの集計が得意です。

2. ストリームデータの変換・加工

例:

IoTセンサーから来る JSON データを正規化して保存

Kafka から受けたイベントをフィルタリングして特定のイベントだけ S3 に送る

ストリームの中から必要な情報を抜き出したり、データを加工して次のシステムに渡せます。

3. 異常検知 (Real-time anomaly detection)

例:

株取引の不正パターンを即検知

IoT センサーの値が一定の閾値を超えたらアラート

Flink の状態管理とパターンマッチングを使って実現可能。

4. リアルタイム ETL

例:

Kafka → Flink でデータをクリーニング → Redshift/S3 へ

データレイクに保存する前に「即座に前処理」を行える。

5. リアルタイムダッシュボード用データ供給

例:

SNS やゲームのユーザー行動をリアルタイムに可視化

モニタリング用ダッシュボードの裏側で使う

❌ あまり向かない処理

バッチ処理（1日1回まとめて実行 → Glue / EMR の方が適切）

超単純な処理（例: 「そのままS3に流すだけ」 → Firehose で十分）

Firehose と Data Streams の違い
Kinesis Data Firehose

ニアリアルタイム（数秒～数十秒単位でバッファリングして転送）

データを そのまま S3 / Redshift / OpenSearch / Splunk に流すのが得意

分析や複雑な処理はできない（シンプルなフォーマット変換程度のみ）

なので「蓄積が目的なら Firehose」「リアルタイム分析は無理」

Kinesis Data Streams

リアルタイム（ミリ秒〜秒単位）でストリームデータを配信

消費側（Lambda, Flink, Kinesis Client Library アプリ）が自由に処理できる

並列処理・スケーラブル

「分析処理を組み合わせられる基盤」として強い

Flink + Data Streams

ここがポイントです。

Data Streams が「データの入り口」

Flink (Amazon Managed Service for Apache Flink) が「リアルタイム分析エンジン」

→ IoT / ログ解析みたいな「加工・集計・異常検知」をやりたいなら、
Kinesis Data Streams → Flink → S3/Redshift/Dashboard という構成がベストプラクティス

Amazon DynamoDB には大きく分けて 2つのスケーリング方法があります。

 1. オンデマンドキャパシティーモード

完全自動スケーリング

事前に RCU/WCU（読み書きキャパシティー）を指定しなくても、トラフィックに応じて自動でスケーリング

例えば「数リクエスト/秒 → 数百万リクエスト/秒」にスパイクしても自動で対応

請求は「実際のリクエスト数に応じて従量課金」
 「予測不能なアクセスパターン」や「短期的に負荷が激しく変わるシステム」に最適

 2. プロビジョンドキャパシティーモード + オートスケーリング

事前に「ベースラインの RCU/WCU」を設定

DynamoDB オートスケーリング が CloudWatch メトリクスを監視し、必要に応じてキャパシティーを自動調整

上限・下限を指定できるので「コストコントロール」も可能
 「ある程度予測できるワークロード」や「コストの上限を制御したいケース」に適している

DynamoDB のキャパシティーモード

プロビジョンド（固定キャパシティー）

ベースラインは安いが、スパイクに弱い

Auto Scaling を有効化すると多少は追従可能だが、スパイクに完全には対応しきれないことがある

オンデマンド（従量課金）

リクエストに応じて自動スケーリング

スパイクに即応できる（数百万 RCU/WCU まで対応可能）

「使った分だけ課金」なので、普段は低負荷・時々スパイクのケースでコスト効率が高い

Amazon Kinesis Data Streams 自体は「データを取り込んで保持するだけ」で、分析や処理ロジックは持ちません。

正しい流れを言い換えると

プロデューサーがデータを Streams に流す

コンシューマー（アプリ or Lambda or Flink） が Streams からデータを取り出す

ここで「リアルタイムデータ処理（整形・集計・フィルタリングなど）」を実行

コンシューマーが処理済みデータを Firehose に渡す

Firehose が S3 / Redshift / OpenSearch などに配送

クロスリージョンレプリケーション (CRR) の仕組み

対象：Amazon S3 バケット

動作：オブジェクトが作成・更新されたときに、自動的に別リージョンのバケットにコピーされる

レプリケーションされるイベントは主に以下：

PUT（新規アップロード）

COPY（コピー）

オブジェクトの更新（上書きアップロード）

レプリケーションされないケース

レプリケーション設定前にすでに存在しているオブジェクト（ただし「既存オブジェクトコピー機能」を使えば可能）

削除操作（DELETE）

デフォルトでは削除はレプリケーションされない

ただし「削除マーカーのレプリケーション」を有効にすれば、バージョニング環境では削除も同期できる

「CRR は常に同期してるわけではなく、イベントが発生した時点で非同期に複製される」

レイテンシは数秒〜数分かかることがある（リアルタイムではない）

クロスリージョンレプリケーションは「オブジェクト作成や更新時」に発火し、非同期で複製される
 削除はデフォルトではレプリケートされない（必要なら設定が必要）

手動で実行するケースがある理由

CRR は 新規オブジェクト作成・更新時のみ 自動で複製します。
→ つまり 既存オブジェクト は自動ではコピーされません。

そのため、以下のようなケースで手動実行が必要になります。

手動実行が必要になるケース

既存バケットをレプリケーション対象にしたいとき

すでに数百万ファイルあるバケットに CRR を設定しても、新しいオブジェクトしか同期されない

→ 既存分を aws s3 cp や aws s3 sync でコピーしておく必要がある

レプリケーションが失敗したオブジェクトを補填したいとき

ネットワークエラーや一時的な設定不備で一部がレプリケートされなかった場合、手動コピーで補う

削除のレプリケーションを制御したいとき

CRR はデフォルトでは削除を同期しない（削除マーカーはオプション）

手動で「不要オブジェクトを消す」運用をする場合がある

S3 バージョニング + ライフサイクルポリシー

バージョニング有効化

オブジェクトを更新すると「新バージョン」が作成され、古い方は「旧バージョン」として残る

ライフサイクルルール

「オブジェクトが特定の状態になってから ○日後 にアクションを実行」する仕組み

対象にできるのは：

現行バージョン（current version）

旧バージョン（non-current version）

S3 ライフサイクルポリシーのトリガーまとめ
1. オブジェクト作成からの日数

オブジェクトがバケットに アップロードされた日 を起点にカウント

例：30日後に Standard-IA に移行、365日後に削除

2. 非現行バージョン（旧バージョン）になってからの日数

バージョニング有効バケット限定

オブジェクトが 新しいバージョンに置き換えられた日 を起点にカウント

例：非現行化してから30日後に Glacier Deep Archive、730日後に削除

3. 削除マーカーに関する日数

バージョニング有効バケットで DELETE したときに作成される「削除マーカー」が対象

例：削除マーカー作成から30日後に削除マーカーを消す

4. マルチパートアップロード未完了オブジェクト

マルチパートアップロードを開始したが完了しなかったオブジェクトを対象

例：7日後に未完了のアップロードを自動削除

### S3 ライフサイクルトリガー一覧

| トリガーの種類 | 起点になるイベント | 主な用途 |
|--------|--------|--------|
| オブジェクト作成 | アップロード時 | 標準→IA、Glacier などストレージ移行、削除 |
| 非現行バージョン化 | 新バージョンが作成された時 | 旧バージョンのアーカイブや削除 |
| 削除マーカー | DELETE 実行で削除マーカー作成時 | 不要な削除マーカーのクリーンアップ |
| マルチパート未完了 | マルチパート開始から経過日数 | 失敗/放置アップロードの削除 |

---

## CloudFront のオリジンの種類

CloudFront で配信元（オリジン）を指定するとき、主に次の2種類がある

### S3 オリジン (Amazon S3 origin)
- S3 バケットを直接オリジンにする設定
- 静的コンテンツ配信でよく使う
- CloudFront と S3 がネイティブ連携するので簡単＆最適化済み

### カスタムオリジン (Custom origin)
- S3 以外のオリジンを指定する場合の総称
- 例:
  - オンプレミスサーバー
  - EC2 上の Web サーバー（Apache/Nginx）
  - ELB (ALB/NLB)
  - 他社クラウド上のサーバー
- HTTP/HTTPS サーバーとして動作していれば CloudFront のオリジンにできる

## Account Factory とは

- AWS Control Tower の中で新しいアカウントを自動作成・管理する仕組み

### Account Factory の役割

#### 標準化されたアカウント作成
- 組織ルールに従ったIAMロール、ログ設定、ネットワーク設定が自動で入る

#### マルチアカウント展開の効率化
- 手動でアカウントを作るよりも早く安全

#### 既存アカウントの取り込み（Enrolling Accounts）
- すでにある AWS アカウントを Control Tower 管理下に置くことも可能

---

## FSBP (Foundational Security Best Practices)

- AWS が提供している セキュリティベストプラクティス基準
- AWS Security Hub で有効化できるセキュリティ標準の 1 つ
- AWS アカウントやリソースがベストプラクティスに従っているかどうかを自動チェック

### 具体的にチェックされること

#### IAM
- ルートアカウントのアクセスキーが無効か
- MFA が有効化されているか

#### S3
- バケットがパブリックアクセス可能になっていないか
- 暗号化が有効か

#### CloudTrail
- 全リージョンで有効化されているか

#### その他
- Config, GuardDuty, VPC Flow Logs, RDS, Lambda などの各サービスごとにセキュリティベストプラクティスを満たしているか

### Security Hub のセキュリティ標準

- **CIS AWS Foundations Benchmark**：外部標準ベース、よりコンプライアンス寄り
- **PCI DSS**：クレジットカード関連の要件
- **FSBP (Foundational Security Best Practices)**：AWS 独自、幅広く網羅

> FSBP は「AWS が考える必須セキュリティのベストプラクティス集」という位置づけで、一畫よく使われる

---

### Security Hub の役割
「AWS アカウントやリソースのセキュリティ状態がちゃんとしてるかを、自動でチェックして見える化するサービス」

### 役割の違いと補完関係

#### Control Tower + Account Factory
- 新しい AWS アカウントを「会社標準」の設定で自動作成
- 例：ログアーカイブ用アカウント、監査用アカウント、開発部門用アカウント
- ガードレールで最低限のセキュリティ・ガバナンスを強制

#### Security Hub
- 作られたアカウントが「セキュリティ的にちゃんとしてるか」を継続チェック
- FSBP / CIS / PCI DSS などに基づいて合否判定＆スコア化
- 全アカウントを横断的にダッシュボードで可視化

---

### Account Factory の正体
- AWS Control Tower の機能
- 新しいアカウントを自動でプロビジョニングする仕組み
- ただ作るだけじゃなく、セキュリティやガバナンスのルールを最初から組み込んで作成

---

## DynamoDB Streams と Global Tables の関係

### DynamoDB Streams
- テーブルの変更履歴（項目の追加・更新・削除）を時系列でキャプチャする仕組み
- Lambda や Kinesis で処理できる

### DynamoDB Global Tables
- マルチリージョンにまたがって同じテーブルを持つ仕組み
- 裏側では DynamoDB Streams を使って変更を検知 → 他リージョンへ自動反映

### どう動くのか？
1. 東京リージョンのテーブルでアイテムを更新
2. DynamoDB Streams がその変更を検知
3. Global Tables の仕組みが、他のリージョン（例：バージニア）に自動レプリケーション
4. 数百ms〜数秒で他リージョンのテーブルにも反映

### Global Tables の裏側
- DynamoDB Global Tables は、内部的に DynamoDB Streams を利用してマルチリージョン複製を実現
- 各リージョンでのテーブル変更を Streams が検知 → レプリケーション用の仕組みが他リージョンへ非同期で反映