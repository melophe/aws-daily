# S3 Intelligent-Tiering の階層と Glacier の対応関係

## 階層構成

### Frequent Access tier
- S3 Standard 相当

### Infrequent Access tier
- S3 Standard-IA 相当

### Archive Instant Access tier
- Glacier Instant Retrieval 相当
- 「アーカイブ」だけど即時取り出し（ミリ秒単位）可能
- コストは S3 Standard-IA よりさらに安い

### Archive Access tier（オプション）
- Glacier Flexible Retrieval 相当
- 取り出しに数分〜数時間

### Deep Archive Access tier（オプション）
- Glacier Deep Archive 相当
- 取り出しに数時間〜最大48時間

---

## デフォルト構成

Intelligent-Tiering のデフォルトは 1〜3 の3階層（即時アクセス可能な階層だけ）

## オプションで有効化できる階層
- **Archive Access tier**（＝Glacier Flexible Retrieval 相当）
- **Deep Archive Access tier**（＝Glacier Deep Archive 相当）

## 重要ポイント

試験問題のように「SLA＝即時アクセス保証」がある場合は **Archive Access / Deep Archive Access を無効化** するのが正解

## 階層一覧表

| 階層名 | 有効化の要否 | アクセス速度 | 備考 |
|--------|------------|------------|------|
| Frequent Access | 自動有効 | 即時 | S3 Standard 相当 |
| Infrequent Access | 自動有効 | 即時 | Standard-IA 相当 |
| Archive Instant Access | 自動有効 | 即時 | Glacier Instant Retrieval 相当 |
| Archive Access | 手動で有効化 | 数分〜数時間 | Glacier Flexible Retrieval 相当 |
| Deep Archive Access | 手動で有効化 | 数時間〜48時間 | Glacier Deep Archive 相当 |

## EC2 Instance Connect

### 概要

EC2 Instance Connect は「一時的なSSH鍵を安全に発行して接続する仕組み」

Bastionサーバーの代わりにはなるが、SSHプロトコル自体はそのまま使用

### 仕組みの流れ

1. オペレーターが AWS コンソールや CLI で EC2 Instance Connect を実行
2. AWS が一時的な公開鍵を発行
3. その鍵が EC2インスタンスに挿入される（SSM Agent経由）
4. ユーザーのSSHクライアントが TCP/22 で接続

つまり、最終的には「SSHセッションを確立」している

### まとめ

- **EC2 Instance Connect** = SSHを安全に使うための一時鍵配布サービス
- **Session Manager** = SSH自体を使わない安全なリモートシェル環境

「22番ポート閉じたい」「Bastion廃止したい」なら → **Session Manager一択**

## Run Command vs Session Manager の違い

| 項目 | Run Command | Session Manager |
|------|------------|----------------|
| 操作方法 | コマンド単位で送信（例：yum update や systemctl restart nginx） | EC2 にログインしてコマンドを順に実行できる「対話シェル」 |
| 実行の形式 | 非対話型（ワンショット） | 対話型（リアルタイム） |
| ユースケース | 定期メンテ、設定変更、一括アップデート | デバッグ、手動操作、ログ確認、ポートフォワード |
| ポートフォワード | できない | 可能（例：ローカル8080→EC2の3306） |
| 通信 | SSM Agent 経由で HTTPS(443) | 同じく SSM Agent 経由で HTTPS(443) |
| SSHキー必要 | 不要 | 不要 |
| Bastionホスト必要 | 不要 | 不要 |
| ログ出力 | CloudWatch Logs / S3 に保存可能 | 同様に保存可能（セッション記録） |
| 同時操作性 | 1回のコマンドのみ実行 | 対話セッションで複数コマンド連続実行可能 |
| 権限 | ssm:SendCommand | ssm:StartSession, ssm:StartPortForwardingSession など |
| 例 | aws ssm send-command --document-name "AWS-RunShellScript" --targets Key=instanceIds,Values=i-xxxx | aws ssm start-session --target i-xxxx |

---

## Session Manager vs Client VPN

### 両者の目的の根本的な違い

| 項目 | Session Manager | Client VPN |
|------|----------------|-----------|
| 主な目的 | EC2 やオンプレサーバーを安全に操作（運用・デバッグ） | 社員や開発者のPCを VPC 内に接続（ネットワークアクセス） |
| できること | 対話シェル、ポートフォワード（例:8080→3306） | AWS内部リソースへのアクセス（EC2/RDS/VPC内Webなど） |
| 対象範囲 | 個々の EC2 インスタンス単位 | VPC全体（サブネット単位） |
| 通信レベル | OSレベル（インスタンス内部） | ネットワークレベル（VPC全体にルーティング） |
| VPNトンネル | なし（SSM API経由） | あり（OpenVPN over TLS/SSL） |
| 認証方式 | IAM ポリシー + SSM権限 | IAM / AD / 証明書認証など多様 |
| ポート要件 | 443（HTTPSのみ） | 443（OpenVPN/TLS） |
| ログ監査 | CloudWatch Logs / S3（セッション記録） | CloudWatch Logs（接続ログ） |
| 操作イメージ | AWS CLI や コンソールから start-session | AWS VPNクライアントを起動して接続 |

---

## ディザスターリカバリの種類

### オンプレミス→オンプレミス
- 例：カリフォルニアとシアトルにデータセンターを持つ
- 従来型で非常に高コスト

### ハイブリッドリカバリ
- メインはオンプレミス、災害時にクラウドを利用

### クラウド→クラウド
- 例：AWSのリージョンAからリージョンBへ
- 完全クラウド型の災害復旧

---

## 重要な用語

### RPO（Recovery Point Objective）
- 「どれだけのデータ損失を許容できるか」
- バックアップ間隔を示す
- 例：1時間ごとにバックアップ → 災害時に最大1時間分のデータを失う可能性

### RTO（Recovery Time Objective）
- 「どれくらいのダウンタイムを許容できるか」
- 災害発生からシステム復旧までの時間

**RTO/RPOを短くするほどコストは高くなる**

---

## AWSにおける主なディザスターリカバリ戦略

| 戦略名 | 概要 | コスト | RTO/RPO |
|--------|------|--------|---------|
| 1. Backup & Restore | 定期的にバックアップを取り、災害時にリストア | 低い | 高い（復旧に時間がかかる） |
| 2. Pilot Light | 重要コア部分のみ常時稼働 | 中 | 中（速い復旧が可能） |
| 3. Warm Standby | システム全体を縮小版で常時稼働 | 高い | 低い |
| 4. Multi-Site / Hot Site | 本番システムを完全に二重化（Active-Active） | 非常に高い | 非常に低い（秒〜分単位） |

---

## 実践

### バックアップ
- EBS/RDSスナップショットをS3・Glacierに保存
- ライフサイクルポリシーやクロスリージョンレプリケーションを活用
- オンプレ→AWSへはSnowballやStorage Gateway

### 高可用性
- Route 53でリージョン間DNSフェイルオーバー
- RDS Multi-AZ、EFS、ElastiCache Multi-AZなどの活用

### ネットワーク冗長
- Direct Connect＋VPNでバックアップ経路を確保

### 自動化
- CloudFormation / Elastic Beanstalk で環境再構築を自動化
- CloudWatch＋Lambdaで障害時の復旧を自動トリガー

### カオステスト
- Netflixの「Simian Army / Chaos Monkey」のように、意図的に障害を起こして耐障害性を検証

---

## Pilot Light

AWSの災害対策（DR: Disaster Recovery）戦略の"構成パターン（設計手法）"

### Pilot Lightを実現するAWSサービスの例

Pilot Light自体はサービスではなく設計思想だが、その構成をAWS上で実現するために以下のようなサービスを組み合わせる

| 機能 | 使用するAWSサービスの例 |
|------|----------------------|
| データ同期 | AWS Elastic Disaster Recovery（DRS）、AWS Backup、Database Migration Service（DMS） |
| インフラ自動復旧 | CloudFormation、Elastic Beanstalk |
| DNS切り替え | Route 53（フェイルオーバールーティング） |
| ストレージ | Amazon S3、EBS |
| モニタリング | CloudWatch、EventBridge |

## マルチサイト（Multi-Site / Hot Site）

### 概要

マルチサイト構成とは、**2つ以上の拠点（リージョンやデータセンター）で本番環境を同時稼働させる構成**

別名 **Hot Site** や **Active-Active構成** とも呼ばれる

### 目的

- システムの**可用性（Availability）**を最大化
- 災害発生時の復旧時間（RTO）を最小化
- データ損失（RPO）をほぼゼロにする

### 構成要素ごとの役割

#### ① Route 53（DNSフェイルオーバー）

- Active-Active構成では、Route 53 の Latency Routing または Geo DNS を使用
- 片方のリージョンが障害を検知したら、自動でトラフィックを健康な側へルーティング
- ヘルスチェック機能により自動で切替を行う

#### ② データベース（Aurora Global Database）

- **プライマリDB** → 東京リージョン
- **セカンダリDB** → オレゴンリージョン（1秒未満の遅延でレプリケーション）
- フェイルオーバー時は数十秒でセカンダリを昇格可能
- **RPO ≒ 0秒、RTO ≒ 数十秒**という非常に高い耐障害性

#### ③ ストレージ（S3）

- S3 Cross-Region Replication (CRR) を使用して、データを自動的にもう一方のリージョンにコピー
- 例：ap-northeast-1（東京）→us-west-2（オレゴン）

#### ④ アプリ層（EC2 / ALB / Auto Scaling）

- 各リージョンに同一構成のアプリケーション環境を構築
- トラフィック分散はRoute 53またはCloudFrontが担当
- Auto Scalingにより両リージョンで負荷分散を維持

## Aurora Global Database 構成

Aurora Global Databaseは「1つのプライマリ」と「複数のセカンダリ（リードオンリー）」という構成

### 全体構成図

```
┌──────────────┐
│ 東京リージョン（プライマリ） │ ← 書き込み可
│   └─ Writerノード             │
│   └─ Readerノード             │
└──────────────┘
             │
             │（遅延1秒未満のレプリケーション）
             ▼
┌──────────────┐
│ オレゴンリージョン（セカンダリ） │ ← 読み取り専用（書き込み不可）
│   └─ Readerノード             │
└──────────────┘
```

### 基本動作

- 東京（プライマリ） → オレゴン（セカンダリ）へデータが非同期レプリケーション
- オレゴン側のアプリケーションは「SELECT（読み取り）」は可能
- 「INSERT / UPDATE / DELETE（書き込み）」は不可

### オレゴンのユーザーがフォーム送信や投稿したいときは？

アプリケーションが「オレゴンのユーザーからの書き込みリクエストを東京のプライマリに送る」ように設計する必要がある

#### リクエスト処理の設計

- **読み込み系（GET系API）**: 最寄りのリージョン（オレゴン）でOK
- **書き込み系（POST/PUT/DELETE系API）**: プライマリ（東京）へリクエスト転送

多くの企業は **API Gateway + Route 53 + ALB** の組み合わせで「書き込みリクエストだけプライマリに送る」ように設計

### フェイルオーバー時の動作

もし東京リージョンがダウンした場合：

1. オレゴンのセカンダリを「プライマリに昇格（Promote）」
2. 書き込みが可能になる（RTOはおおむね1分以内）

つまり、「普段は片方向同期だが、災害時には切り替えて双方向的に使える」仕組み

---

## Elastic Disaster Recovery (DRS)

| 比較項目 | Elastic Disaster Recovery (DRS) の位置づけ |
|----------|-------------------------------------------|
| DRパターン | Pilot Light |
| 主な目的 | 復旧時間を数分に短縮しつつ、平常時コストを最小化 |
| 強み | 自動復旧、リアルタイム同期、EBSブロックレベルレプリケーション |
| 弱点 | 平常時に完全な本番環境が存在しない（Warm Standbyほど即時ではない） |
| 他サービスとの関係 | Backup & Restore より高速、Warm Standby より低コスト |

---

## ウォームスタンバイ用EC2

### ポイント

| 特徴 | 説明 |
|------|------|
| 常時起動 | "Warm"＝冷たくない → 停止ではなく動作中 |
| 低コスト運用 | インスタンスサイズを小さくしてコスト最小化 |
| スケーラブル | 災害時はAuto ScalingやElastic Beanstalkで即拡張 |
| フェイルオーバー | Route 53 や Elastic Load Balancing でトラフィック切替 |
| 利用サービス | EC2, RDS, Auto Scaling, Route 53, CloudWatch, Lambdaなど |

### 重要ポイント

「ウォームスタンバイ（Warm Standby）」の "ウォーム" は比喩であって、実際はEC2インスタンスは "普通に起動している" 状態

インスタンスタイプを拡張し、本番用スケールに切り替える

### 用語の違い

- **ウォームスタンバイ** → 災害対策（DR）構成の名前。常に小規模で起動しておく
- **ウォームアップ（warm-up）** → Auto ScalingやLambdaの文脈で「最初のリクエスト遅延を防ぐために、あらかじめ起動しておく」処理のこと

ウォームスタンバイ構成は、EC2を小さいサイズで常時起動しておき、災害時にAuto ScalingやLaunch Templateの更新で本番レベルに拡張できる

### 構成例

#### 平常時
- 小さなインスタンスタイプ（例：t3.micro）
- Desired = 1, Min = 1, Max = 1
- Route 53でトラフィックはオフ

#### 災害発生時
- Route 53フェイルオーバーでAWS側へトラフィックを切替
- Auto Scalingグループの設定を変更
- 必要に応じてインスタンスタイプをスケールアップ（Launch Template切替）

### Launch Template管理

ウォームスタンバイ構成では、災害時にすぐスケールアップできるように、あらかじめ複数の Launch Template（または Launch Template のバージョン）を用意しておくのが一般的

#### 理由：災害時に「即座に切り替え」るため

ウォームスタンバイ構成では平常時は低コスト運用（例：t3.micro）だが、障害時にいちいち手動でEC2タイプを変えたりAMIを編集したりしていたら、RTO（復旧時間目標）を満たせない

#### ベストプラクティス

- **事前に「本番用テンプレート」と「スタンバイ用テンプレート」**を作っておく
- Launch Template Version で切り替えをスクリプト化しておく

### 構成の例

| 状況 | Launch Template名 | バージョン | 主な設定 |
|------|------------------|-----------|----------|
| 平常時（スタンバイ） | web-asg-template | v1 | EC2タイプ：t3.micro / 最小構成 |
| 災害時（スケールアップ） | web-asg-template | v2 | EC2タイプ：m5.large / 本番性能構成 |

### 推奨設定

- Launch Templateを複数バージョンで管理（v1=スタンバイ、v2=本番）
- Auto Scaling Groupは共通（テンプレートだけ切り替える）
- 災害検知時にEventBridge or Lambdaで自動切替
- Route 53フェイルオーバー設定で自動トラフィック転送

---

## AppStream 2.0

### 概要

AWSが提供するマネージド仮想デスクトップ配信サービス

### 特徴

- 各リージョンに展開でき、アプリケーションの画面をストリーミング配信
- ユーザー体験が均一になり、グローバル展開に強い

---

## S3 Transfer Acceleration（S3TA）

### 概要

Amazon S3 Transfer Acceleration（略して S3TA）は、「S3 へのアップロード／ダウンロード時のレイテンシを減らす」ための機能

### 仕組み

#### 従来の通信
- クライアント → 東京リージョン（例: s3.ap-northeast-1.amazonaws.com）へ直接通信
- 距離が遠いほどレイテンシ（遅延）やパケットロスが増える

#### S3TAを有効化すると
1. クライアント → もっと近い CloudFrontエッジロケーション にまず接続
2. そこから AWS の高速・最適化されたバックボーンネットワーク経由で S3バケット（東京リージョンなど）へデータを転送

### 通信経路の比較

- **従来**: ユーザー（シンガポール） → [インターネット経由] → 東京S3
- **S3TA**: ユーザー → [近くのエッジ（例：シンガポール）] → [AWS内部ネットワーク] → 東京S3

AWSの内部ネットワークはインターネットよりも高速・安定しているため、転送速度が平均で50%〜数倍速くなることもある

### 効果が出るケース

| 条件 | 効果 |
|------|------|
| クライアントが海外・遠距離にある | 劇的に高速化 |
| ネットワークが不安定（モバイル回線など） | 再送リスク減 |
| アップロードが大容量（GB〜TB級） | 効果大 |
| 同一リージョン内通信 | 効果ほぼなし（むしろコストだけ増える） |

### 設定ポイント

- **エンドポイントが変わる**: 例）mybucket.s3-accelerate.amazonaws.com
- 有効化はS3バケット単位
- 追加料金あり（通常S3通信より少し高い）

---

## マルチパートアップロード

### S3の通常PUT制限

| 項目 | 内容 |
|------|------|
| 通常のPUTリクエスト | 最大 5GB までしかアップロードできない |
| マルチパートアップロード | 最大 5TB（＝5000GB） まで対応可能 |

「5GBを超えるファイルをS3にアップロードする場合は、マルチパートアップロードが必須」

### 高速化の組み合わせ

- **S3 Transfer Acceleration**（Amazon CloudFrontのエッジ経由で最適ルートを使う）
- **マルチパートアップロード**（並列送信）

この2つを併用すると、地球の裏側からでも高速・安定したアップロードが可能

マルチパートアップロード = 速くて切れにくいS3転送

## Lambda イベントソースマッピング（Event Source Mapping）

### 概要

「Lambda のイベントソースマッピング（Event Source Mapping）」は、AWS Lambda が外部のイベントソース（＝データの発生源）を自動的にポーリングして処理する仕組み

**一言で言えば**: 「Lambdaが自動でデータを拾いに行く設定」

### 動作例

たとえば、SQSにメッセージが届いたときに:
1. それを自動で検知して
2. Lambdaを起動し、処理してくれる

という流れを Lambdaが勝手にやってくれるのがイベントソースマッピング

### 対応している主なイベントソース

| イベントソース | Lambdaの動作 |
|--------------|-------------|
| Amazon SQS | メッセージを自動でポーリングして1件ずつ（またはバッチ）処理 |
| Amazon Kinesis Data Streams | ストリームのレコードを自動で取り込み、順次処理 |
| Amazon DynamoDB Streams | テーブル変更イベントを拾って処理 |
| Amazon MSK (Kafka) | Kafkaトピックを自動購読して処理 |

### 処理フロー例

1. API Gateway → SQS にメッセージを送信
2. LambdaがSQSを自動ポーリング（イベントソースマッピング）
3. メッセージを受け取ると Lambdaが実行される
4. 処理が終わると自動的にメッセージを削除

### メリット

- **SQSにためておける**（スパイク吸収）
- **Lambdaは自動スケール**
- **運用不要**（サーバーレス）

### まとめ

「LambdaがSQS（やKinesis、DynamoDB Streamsなど）を自動ポーリングしてイベントを検知→実行する仕組み」を "イベントソースマッピング（Event Source Mapping）" と呼ぶ

### 自動スケール

Lambda は SQS キューの深さ（メッセージ数）に応じて自動スケール

#### 仕組みの概要

Lambda と SQS をイベントソースマッピングで連携すると、AWS が裏で「ポーリング＋並列実行の制御」を自動で行う

#### スケール動作

1. SQS のメッセージが増える
2. Lambda が並列で複数インスタンスを自動起動（＝スケールアウト）
3. メッセージが減ると自動でインスタンスが停止（＝スケールイン）

## Hadoopとは

「大量データを分散処理するための仕組み（フレームワーク）」

Hadoop = 分散処理の基礎技術セット

### 主要コンポーネント

| コンポーネント | 役割 |
|--------------|------|
| HDFS (Hadoop Distributed File System) | 複数サーバーにまたがってファイルを分割保存する分散ストレージ |
| YARN (Yet Another Resource Negotiator) | クラスタ内のリソース（CPU、メモリ）を管理 |
| MapReduce | データ処理を「分割（Map）」と「集約（Reduce）」に分けて並列実行 |

### AWSでの位置づけ

AWSでは、これらを簡単に使うためにマネージド化したのが以下のサービス

| サービス | 内容 |
|---------|------|
| Amazon EMR | Hadoop/Sparkを簡単にデプロイ・スケールできるマネージドサービス |
| Amazon Glue | SparkベースのサーバーレスETLサービス（スクリプト不要でデータ変換） |

---

## PySparkとは

「Apache SparkをPythonで使うためのAPI（ライブラリ）」

Spark自体はScalaで書かれたフレームワークだが、Pythonでも使えるようにしたのが PySpark（パイスパーク）

つまり「PythonからSparkの分散処理を操るためのツール」

---

## Hiveスクリプトとは

「SQLっぽい文法でHadoop上のデータを扱うための仕組み」

Apache Hive は Hadoop の上に構築された データウェアハウスツール

HDFS（分散ストレージ）上のデータを SQL風に操作できる

### 「PySpark + Hiveスクリプト」とは

多くの企業では Hadoop クラスタ上で以下のように運用している

- Hive により「SQLライクにデータ抽出」
- PySpark により「抽出後のデータを分散分析 or ETL処理」

つまり「Hiveでクエリ → PySparkで分析・変換」という連携

### まとめ

| 用語 | 役割 |
|-----|------|
| PySpark | SparkをPythonで操作するためのAPI。分散データ処理用 |
| Hive | Hadoop上でSQL風にクエリを実行するツール |
| HDFS | Hadoopの分散ファイルシステム |
| 組み合わせると | HDFS上のデータをHiveで抽出 → PySparkで加工・分析 |

---

## 使い分けの指針：EMR vs Redshift

| 観点 | EMR | Redshift |
|-----|-----|----------|
| 主目的 | バッチ処理・ETL・ML | データ分析・BI |
| データ形式 | 非構造・半構造もOK | 構造化データ |
| ストレージ | S3を使う | Redshift内部ストレージ |
| クエリ言語 | PySpark, HiveQL, etc | SQL |
| スケーリング | クラスタを都度起動（Auto Scaling可） | ノード自動スケール（Serverlessあり） |
| コスト | 使った分だけ（スポット利用可） | 常時課金（従量課金も可） |
| 運用 | Hadoop/Spark構成理解が必要 | ほぼ完全マネージド |

---

## Amazon EMR の２つの使い方

| 処理タイプ | 主な技術 | 内容 |
|----------|---------|------|
| バッチ処理 | Hadoop / Spark / Hive / Presto | 数時間かけてまとめてデータを処理（典型的な夜間バッチなど） |
| ストリーミング処理 | Spark Structured Streaming | 継続的にデータを取り込みながらリアルタイム分析する |

### Spark Structured Streaming とは

EMR の上で使える Apache Spark の機能のひとつで、Kinesis Data Streams や Kafka などからデータをリアルタイムで取り込み、処理・集計・可視化できる フレームワーク

つまり EMR + Spark Structured Streaming を使うと、Kinesis → Spark (on EMR) → DynamoDB / S3 / Redshift のようにデータを流しながらリアルタイム集計が可能

### どういうときに使う？

| ケース | 向いているサービス |
|-------|----------------|
| 単純なリアルタイム処理（軽い集計・少量データ） | Kinesis + Lambda + DynamoDB |
| 複雑な処理（複数ストリーム結合・機械学習前処理など） | EMR + Spark Structured Streaming |

EMR は本来「バッチ処理」メインだが、Spark Structured Streaming を使えば リアルタイム処理も可能

---

## 各サービスのログ分析スタイル比較

| 観点 | Amazon Kinesis | Amazon EMR | Amazon Redshift |
|-----|---------------|-----------|----------------|
| 処理タイプ | ストリーミング（リアルタイム） | バッチ／ストリーミング（どっちも可） | バッチ（静的データ分析） |
| 主な用途 | リアルタイムログ監視、アラート、ダッシュボード更新 | 大量ログの集計・機械学習・ETL処理 | 既に蓄積されたデータを高速に分析・可視化 |
| データソース例 | CloudWatch Logs, IoT, Webアクセスログなど（秒単位） | S3上のログファイルやKinesisストリーム | S3またはETL済みのデータ（DWH向け） |
| スケール特性 | 秒単位で自動スケール（常時稼働） | スポット起動・Auto Scaling（必要時のみ起動） | ノード数スケール（常時稼働） |
| コスト | 低コスト（秒課金） | 中コスト（起動時だけ課金） | やや高コスト（常時起動） |
| 分析のタイミング | 今すぐ（リアルタイム） | 数分〜数時間ごと（バッチ） | 定期レポート／BIツール連携（後日） |
| 代表的な組み合わせ | Kinesis Data Streams → Kinesis Data Analytics → DynamoDB / CloudWatch | S3 + EMR + Spark / Hive | S3 + Redshift + QuickSight |

---

## ETL処理の流れ

アプリのログを収集（E） → 日付ごとに集計（T） → Redshiftにロード（L）

### 3サービスそれぞれの ETL 特性

| サービス | ETLの役割 | 得意な処理タイプ | 適したデータ量 | 特徴 |
|---------|----------|----------------|--------------|------|
| Kinesis | E（抽出）＋L（ロード）中心 | リアルタイムストリーミングETL | 秒〜分単位、リアルタイム | Kinesis Firehoseで取り込みと変換を自動実行 |
| EMR | T（変換）中心 | バッチETL（Hadoop/Spark） | 数十GB〜数TB以上 | S3上のデータを並列処理して整形・集計 |
| Redshift | L（ロード）＋一部T（変換） | DWH内ETL（SQL変換） | 集約済みデータ | COPYコマンドやSQLで変換処理が可能 |

### Kinesis Firehose

- データをリアルタイムでストリーム取り込み
- Lambda で簡単な変換（Transform）
- S3 / Redshift / OpenSearch などにロード（Load）

### EMR (Spark / Hive)

- バッチで大量データをまとめて変換する ETL 向き
- 特に「S3に貯めたログを日次で整形」みたいな用途

### Redshift

- すでにロード済みのデータをSQLで再変換（ELTとも呼ぶ）
- CREATE TABLE AS SELECT ... で分析用データセットを作る

---

## Redshiftの本質

**Redshiftは「データ分析基盤（DWH）」**であって、「生データを処理するETLエンジン」ではない

Redshiftは基本的にこう使われる

1. S3などに保存されたデータを
2. COPYコマンドなどでRedshiftにロードして
3. SQLで集計・JOIN・分析して
4. BIツール（QuickSightなど）で可視化する

### Redshiftが得意なのは「分析後半」

| ETLフェーズ | 向いているAWSサービス |
|-----------|-------------------|
| E（抽出） | Kinesis Firehose, Glue, DMS |
| T（変換） | EMR（Spark）や Glue |
| L（ロード） | Redshift COPY, Glue Job |
| 分析／可視化 | Redshift + QuickSight |