# Cron と AWS でのスケジューリング

## Cron とは

**「時間ベースのジョブスケジューラ」**

指定した時間・間隔でコマンドやスクリプトを自動で実行してくれる仕組み

### Cron の概要

- Linux/Unix 系 OS に標準で入っている**デーモン（常駐プログラム）**
- **役割**: 時間ベースでコマンドやスクリプトを自動実行
- その cron に「どのコマンドを、いつ実行するか」を設定するのが **cronジョブ**

## cron と crontab の違い

| 項目 | 説明 | 詳細 |
|------|------|------|
| **cron** | バックグラウンドで動き続けるサービス | `systemctl status cron` で確認可能 |
| **crontab** | ユーザーが cron に渡す「スケジュール表」 | `crontab -e` で編集してタスクを登録 |

### 例
```
0 2 * * * /home/ubuntu/backup.sh
```

### まとめ
- **cron** = Linuxの仕組み（サービス／デーモン）
- **crontab** = cronの設定ファイルを編集するコマンド
- **「cronジョブ」** = crontab に登録された定期タスクのこと

> **Note**: 正確には コマンドというより"サービス"や"仕組み"だが、crontab コマンドを使って操作する

### 使用例

- **毎日深夜にバックアップを取る**
- **毎時ログを集計する**  
- **毎週レポートをメール送信する**

### Cron 式の構成
```
分 時 日 月 曜日 コマンド
```

## AWS でのスケジューリング方法

### 1. EC2で普通にcronを使う

#### 特徴
- EC2はLinuxなので、普通に `crontab -e` でCronジョブを登録可能
- **デメリット**: インスタンス依存（止めたら動かない、冗長化も自分で管理）

### 2. AWS Lambda + EventBridge（おすすめ）

#### 概要
Amazon EventBridge（旧 CloudWatch Events）で cron式を設定可能

#### 例
```
cron(0 2 * * ? *) → 毎日午前2時にLambdaを実行
rate(5 minutes) → 5分ごとに実行
```

#### メリット
- Lambda関数に処理を書けば、EC2を立てなくてもサーバーレスで動く
- **小さいジョブ（バッチ、定期タスク）なら一番綺麗**

### 3. AWS Batch / Step Functions

#### 用途
大規模なバッチ処理なら AWS Batch や Step Functions を EventBridge から起動

**例**: 「毎週末に大量のデータ処理」みたいなケースに向いている

### 4. ECS（コンテナ）のScheduled Task

#### 仕組み
- Fargate/ECSでも**スケジュールタスク**が作れる
- EventBridgeで「cron式」を設定 → ECSタスクを定期的に実行
- **コンテナベースで処理をスケジューリング**したいときに使う

## 推奨パターン

| パターン | 特徴 | 推奨度 |
|----------|------|--------|
| **EC2内のcron** | 従来のやり方、だけどAWSらしさはない | △ |
| **EventBridge + Lambda/ECS** | AWSのマネージドでおすすめ | ◎ |
| **Batch/Step Functions** | 複雑なワークフローや大規模バッチ向け | ○ |

## プレイスメントグループ

### 概要

**EC2インスタンスを起動するときに「どこに配置するか」のポリシーを選択できる機能**

### プレイスメントグループの種類

- **Cluster（クラスタ配置）**
- **Partition（パーティション配置）**
- **Spread（スプレッド配置）**

## クラスタプレイスメントグループ

### 特徴

**同じAZの中でインスタンスを物理的に近接配置する戦略**

### メリット

- **低レイテンシ・高帯域幅のネットワーク通信**が可能
- **インスタンス間で数十Gbpsのスループット**を実現できる（ENA対応インスタンス）

### デメリット

- **同じラックに集める**ので、同時に障害を受けるリスクがある（高可用性は低い）

### 用途

**「インスタンス間通信が速いことが重要」なケース**に使う

## プレイスメントグループの比較

| 種類 | 配置ポリシー | 特徴 |
|------|-------------|------|
| **Cluster** | 同じラックに近接配置 | 低レイテンシ・高スループット、障害ドメインが小さい |
| **Partition** | パーティションごとに分散配置 | 大規模分散システム（HDFS, Cassandra）に向く |
| **Spread** | インスタンスを物理的に分散配置 | 高可用性重視、少数インスタンス向け |

## ストレージの種類

### ブロックレベル（Block-level Storage）

#### 概要
**ディスクの最小単位（ブロック）で読み書きする方式**

- OSからは「生のディスク」として見える
- その上に**ファイルシステム**（ext4, XFS, NTFSなど）を自分で作る必要がある

#### 特徴
- **高速で柔軟**（DBなど小さい単位でランダムアクセスに強い）
- **EC2のEBSはこのタイプ**
- **SAN(Storage Area Network)** もブロックストレージ

#### 例
- **EBS** (gp3, io2 など)
- **ローカルSSD** (Instance Store)

### ファイルレベル（File-level Storage）

#### 概要
**ファイル単位でアクセスする方式**

- **すでにファイルシステムが用意**されており、マウントしてすぐ利用できる
- **NFSやSMBなどで複数マシンから同時にアクセス**可能

#### 特徴
- **ファイル共有が簡単**（Webサーバー複数台から同じファイルを見るなど）
- ただし、**ブロックストレージより遅い場合が多い**
- **NAS(Network Attached Storage)** がこのタイプ

#### 例
- **Amazon EFS**（NFS互換）
- **オンプレNAS**

### オブジェクトレベル

#### 概要
**オブジェクト単位でアクセス**

- ファイル名や階層ではなく「**キー（ID）**」で管理
- **無限にスケール**するけど、細かい更新や低レイテンシには不向き

#### 例
- **Amazon S3**
- **OpenStack Swift**

## ストレージ種類の比較

| 種類 | 単位 | AWSの例 | ユースケース |
|------|------|---------|-------------|
| **ブロックレベル** | ディスクのブロック | EBS | データベース、低レイテンシI/O |
| **ファイルレベル** | ファイル | EFS | 複数EC2でのファイル共有 |
| **オブジェクトレベル** | オブジェクト（キー＋データ） | S3 | バックアップ、大容量データ配布 |

## Data Firehose の特性

**Data Firehoseはデータロードに最大60秒を要するため、ミリ秒単位の処理には不向きだが、データ変換とニアリアルタイムのデータ配信処理に優れている**

## Amazon SQS の優先度設定

**2つのAmazon SQSキューを作成して、ユーザータイプに応じた処理優先度を設定可能**

- **有料ユーザー**: 優先的に処理するキューを設定
- **無料ユーザー**: デフォルトのキューを設定

> **Note**: Amazon SQSでは、キューに優先度を設定することが可能

## Kinesis Data Streams

### 概要

**リアルタイム処理向けのストリーミングサービス**

**数百ミリ秒レベルの遅延**でデータを取り込んで処理できる

### 仕組み

1. **Streams がデータを受け取る**
2. **コンシューマ**（Lambda, EC2アプリ, Kinesis Client Library, Kinesis Data Analyticsなど）がすぐに読み取って処理
3. データは**シャード単位**で分散して保存され、**デフォルトで24時間（最大7日）保持**される

> **Point**: 過去データを再処理できるのもFirehoseとの違い

## Kinesis Streams と Firehose の比較

| 項目 | Kinesis Data Streams | Kinesis Data Firehose |
|------|---------------------|----------------------|
| **処理方式** | リアルタイム（ミリ秒単位） | バッファリング後に配信（数秒〜分） |
| **データ保持** | 24時間〜7日間保持 | 保持せず即配送 |
| **処理** | コンシューマ（自分で処理を書く） | Lambda変換など簡易加工のみ |
| **出力先** | Lambda, EC2アプリ, Analytics, Firehoseなど自由 | S3, Redshift, OpenSearch, HTTP, Splunk |
| **ユースケース** | 株価、IoT、ゲームイベントなど即時処理 | ログ収集・分析基盤へのバッチ投入 |

## まとめ

- **Streams** = 本格的なリアルタイム処理（自前でコンシューマを作れる）
- **Firehose** = 取り込み後すぐ保存する簡単ストリーム→S3変換装置（リアルタイムっぽいバッチ）

## IoT データパイプライン構築

### データ収集
**AWS IoT Core**
- デバイス認証付きでMQTTやHTTP経由でセンサーデータを収集

### ストリーミング処理
**Kinesis Data Streams**（リアルタイム処理用に）
- LambdaやKinesis Data Analyticsで即時処理・フィルタリング

### 蓄積 & 形式変換 & 保存
**Kinesis Data Firehose**
- 取り込んだデータを **Lambda変換でParquet/ORC に変換**
- その後 **Amazon S3 に保存**（コスト効率良く、AthenaやRedshift Spectrumで分析可能）

## サービス組み合わせパターン

### アーキテクチャ図
```
IoTデバイス → AWS IoT Core → Kinesis Data Streams → Firehose(Lambda変換) → S3
                                     │
                                     └→ Kinesis Data Analytics / Lambda でリアルタイム処理
```

### 各サービスの役割
- **IoT Core**: 安全かつスケーラブルにセンサーデータ収集
- **Kinesis Data Streams**: リアルタイム処理（アラートや可視化に利用）
- **Firehose**: バッファリング・形式変換・コスト効率の良いS3保存
- **S3**: データレイク（Athena, Redshift, Glueで後続分析が容易）

### 使い分けまとめ
- **「リアルタイム処理」** = Kinesis Data Streams
- **「形式変換して安価に保存」** = Firehose → S3

## DynamoDB DAX の構成

**DynamoDBは、デフォルトの設定ではリードレプリカを増加は無理。しかし、DAX有効にしたらDAXクラスターは1つのプライマリノードと、0から9個のリードレプリカノードを構成することが可能**

## ECS キャパシティプロバイダー

### 1. EC2起動タイプの場合

#### 基本構成
- **EC2 Auto Scaling グループ**と結びつける
- どの ASG を使ってインスタンスを増減するかを ECS に教える

#### 例
- **ASG-A**（m5.large × 2台）
- **ASG-B**（c5.xlarge × 3台）

→ ECS はタスクの配置時にどの ASG を使うかを **Capacity Provider 戦略**で判断

> **Point**: 「EC2インスタンスのキャパシティを ECS から制御」できる

### 2. Fargate起動タイプの場合

#### デフォルトプロバイダー
- **Fargate** と **Fargate Spot** がデフォルトのキャパシティプロバイダーとして存在する

#### 料金タイプの選択
- どちらをどの割合で使うかを指定できる
- **例**: Fargate: 70%、Fargate Spot: 30%
- タスク起動時に自動的に割り振ってくれる

> **Point**: 「Fargateの料金タイプを ECS に選ばせる」イメージ

### なぜ ASG をキャパシティプロバイダーにアタッチするのか？

#### 背景
- **EC2 起動タイプの ECS クラスタ**は「コンテナを動かすための EC2 インスタンス群」が必要
- その **EC2 インスタンス群を Auto Scaling Group (ASG) で管理**すると、インスタンス数を柔軟に増減できる
- でも **ECS は直接 ASG を知らない**ので、「この ASG を使うよ」と ECS に教える役割がキャパシティプロバイダー

#### 役割分担
- **ASG** = 実際にスケールするインスタンスの集合
- **Capacity Provider** = ECS が ASG を使えるようにする"橋渡し"

### 設定の流れ

#### 1. ASG を作る
**例**: Amazon Linux 2 AMI, ECS 最適化 AMI, インスタンスタイプ m5.large × 最小2, 最大10

#### 2. Capacity Provider を作る
- その ASG を **ECS Capacity Provider に関連付ける**
- **Managed Scaling を ON** にすると、ECS がタスク需要に応じて ASG を自動でスケールしてくれる

#### 3. ECS クラスタにアタッチ
- 複数の **Capacity Provider（ASGやFargate）をクラスタにアタッチ**可能

#### 4. サービスやタスク起動時に戦略を指定
**例**: `capacityProviderStrategy: [{ capacityProvider: MyASG, weight: 1 }]`

## キャパシティプロバイダーの詳細

### 1. キャパシティプロバイダー (Capacity Provider)

**リソースの供給元そのものを定義するもの**

つまり「**ECS がタスクを置くために使えるキャパシティ（実行環境）の種類**」を表す

#### 例

##### EC2 起動タイプなら
- **Auto Scaling Group を関連付けた Capacity Provider**
- **例**: EC2-ASG-Provider

##### Fargate 起動タイプなら
- AWS が用意している **FARGATE / FARGATE_SPOT**

> **Point**: 「どこに置けるか」を定義するのがキャパシティプロバイダー

### 2. キャパシティプロバイダー戦略 (Capacity Provider Strategy)

**複数のキャパシティプロバイダーをどう使い分けるかを決めるルール**

タスク起動時に「このクラスタ内でどのプロバイダーに何割流すか」を指定できる

#### 指定できる要素
- **base**: 最低限このプロバイダーに置くタスク数
- **weight**: 残りのタスクを振り分ける比率

#### 設定例
```json
capacityProviderStrategy: [
  { "capacityProvider": "FARGATE", "weight": 1, "base": 2 },
  { "capacityProvider": "FARGATE_SPOT", "weight": 3 }
]
```

#### 動作
- **最低2タスクは FARGATE（オンデマンド）に配置**
- **残りは FARGATE : FARGATE_SPOT = 1 : 3 の比率で配置**

> **Point**: 「どう振り分けるか」を定義するのがキャパシティプロバイダー戦略

### まとめ
- **キャパシティプロバイダー**: 使えるキャパシティの種類（ASG, Fargate, Spot…）
- **キャパシティプロバイダー戦略**: 複数のキャパシティをどう組み合わせてタスクを配置するかのルール

## ALBとASGのヘルスチェック

### ALBヘルスチェックの仕組み

- **ALBはターゲットグループの設定に従って、HTTP(S) / TCP でヘルスチェックを実行**
- **例**: `HTTP:80 /health`
- **健康状態を判定**（Healthy / Unhealthy）
- **Unhealthy が続くと、ALB はそのインスタンスやタスクにトラフィックを振らなくなる**

### ASGのヘルスチェックの種類

**ASGは2種類のヘルスチェックを使える**

#### EC2ヘルスチェック（デフォルト）
- **EC2インスタンスのステータスチェック**（ハードウェアやネットワーク障害など）を確認
- 失敗したら「**Unhealthy**」と判定し、**インスタンスを終了して新規起動**

#### ELBヘルスチェック（ALB/NLB連携）
- **ALBやNLBのターゲットグループのヘルスチェック結果を利用**
- ALBが「このインスタンスは応答しない」と判定したら、**ASGも「Unhealthy」とみなし置き換え**

> **Note**: 両方設定できるが、基本はどちらかを指定して使う

### ALBヘルスチェックとの違い

#### ALBヘルスチェック
**ターゲット（EC2やECSタスク）がリクエストに応答できるか確認**

- **Unhealthyなターゲットにはトラフィックを振らない**

#### ASGヘルスチェック
- **インスタンスが「健全に動いているか」を見て、ダメなら新しいインスタンスを起動する**
- **ELB連携をONにすると「ALBがUnhealthy判定したインスタンス」も自動で置き換え対象になる**

### ALBのヘルスチェック詳細

**ALB（ターゲットグループ）は HTTP/TCP レベルでの疎通確認をするだけ**

- **「/health に 200 OK が返るか」とか、そういうアプリの稼働確認**
- **CPU使用率などのメトリクスは ALB 自身は見ていない**

### ASG のスケーリングに使うメトリクス

- **CPU使用率やメモリ使用率に基づいてスケールするのは CloudWatch メトリクス**
- **ASG のターゲットトラッキングやステップスケーリングで利用するのはこの CloudWatch メトリクス**

> **Point**: **ALB が関わるのは「ターゲットが正常かどうか（Healthy/Unhealthy）」の判定であって、CPUメトリクスではない**

## スケーリングのトリガー

### CloudWatch メトリクス

**ASGは CloudWatchメトリクスを見てスケーリングする**

#### 代表的なメトリクス
- **EC2インスタンスのCPU使用率**（一番よく使われる）
- **ネットワークIn/Out**
- **メモリ使用率**（CloudWatch Agent を入れてカスタムメトリクスとして送信）
- **ディスクIO**など（同じくカスタムメトリクス）

> **Point**: ASGが直接アプリの状態を監視しているわけではなく、**CloudWatchに送られてくるメトリクスを参照**

### ヘルスチェックとの関係

#### 役割の違い
- **ALBヘルスチェックやEC2ステータスチェック**: スケーリングのトリガーにはならない
- **これらは「インスタンスが壊れたときに置き換える」ための仕組み**
- **実際に「増やす／減らす」の判断**: CloudWatchメトリクス

## まとめ

- **ヘルスチェック** = インスタンスの健康状態確認・置き換え
- **CloudWatchメトリクス** = スケーリングの判断基準
- **ALB** = トラフィック振り分けと応答可能性確認
- **ASG** = インスタンス数の自動調整

## ヘルスチェックの詳細

### 1. ALBのヘルスチェック

#### 機能
- **HTTPやTCPでターゲット（EC2やECSタスク）が応答するかをチェック**
- **Unhealthy と判定されたら**そのターゲットに**トラフィックを流さない**

> **Point**: **ロードバランシングの対象から外すのが役割**

### 2. ASGのヘルスチェック

#### ASG自身のヘルスチェック機能

##### EC2ステータスチェック（デフォルト）
- 基本的なインスタンス状態の監視

##### ELBヘルスチェック（ALB/NLB連携）
- **ALB/NLBと連携させる設定が可能**

#### ELBヘルスチェック有効時の動作
**ALBがUnhealthy判定したインスタンスを ASGも「故障した」とみなし置き換える**

## スケーリングとの関係

### スケーリング判断の基準
- **スケーリング判断（増やす/減らす）は CloudWatchメトリクスを見て行う**
- **CPU使用率、ネットワークIn/Out** など
- **ヘルスチェックは関係しない**

### 重要な区別
**ヘルスチェックは「不健康なインスタンスを捨てる」だけで、スケールアウト/インのトリガーにはならない**

## 役割分担まとめ

| 機能 | 役割 |
|------|------|
| **ALBヘルスチェック** | リクエストを流すかどうかを決める |
| **ASGヘルスチェック** | 不健康なインスタンスを置き換える |
| **スケーリング（増減の判断）** | CloudWatchメトリクスで決まる |

## ターゲットグループ

### 概要

**AWSのターゲットグループ (Target Group) は、ALB/NLB でトラフィックを振り分けるための転送先リスト**

### 仕組み

- **ALB / NLB / GWLB は「どこにリクエストを送るか」を直接は知らない**
- 代わりに**ターゲットグループを参照**して、登録されているターゲットにリクエストを分配

### 登録可能なターゲットタイプ

- **EC2インスタンス**
- **ECSタスク**（IPモード / ENIモード）
- **Lambda関数**
- **IPアドレス**（オンプレや他VPCのリソースも可）

## Auto Scaling とEBS データ保持

### 問題

#### Auto Scalingのスケールイン
→ **不要になったEC2インスタンスは終了される**

#### デフォルトのEBSボリューム（ルートボリューム）
→ **インスタンス終了時にデフォルトで削除される設定**になっている

> **結果**: 何も設定しないと**インスタンス終了と同時にデータも消える**

### 要件

**スケールインでインスタンスが削除されても、EBS内のデータを保持する必要がある**

### 解決方法

#### 1. EBSボリュームのライフサイクル設定を変更

- **EC2のルートボリューム設定で「DeleteOnTermination=false」を指定**
- **これによりインスタンスが終了してもボリュームは残る**

#### 2. 別の永続ストレージに退避

**データを別の永続ストレージ（S3, EFS, RDS など）に退避させる設計も考えられる**