# CloudFormation テンプレート間でリソースを参照する方法

## 基本原則

CloudFormation では「1つのスタックで作ったリソースを、別のスタックから直接参照」することはできない

そのために スタック間参照 (Cross-Stack References) という仕組みがある

---

## スタック間参照の方法

### Export (出力)

最初のテンプレートで作成したリソース（例: S3バケット名）を Outputs セクションで Export

### ImportValue (インポート)

2つ目のテンプレートで Fn::ImportValue を使って参照

最初のテンプレートで S3 バケット名を Outputs で Export し、別のテンプレートで Fn::ImportValue を使って参照

---

## Ref の基本

### CloudFormation の組み込み関数
同じスタック内のリソースやパラメータ を参照できる

### 返ってくる値はリソースによって異なる
- S3バケット → バケット名
- EC2インスタンス → インスタンスID
- パラメータ → パラメータの値

### スタックをまたぐ場合
Ref では 別スタックのリソースは参照できない

この場合は → Outputs で Export → 別スタックで Fn::ImportValue

---

## まとめ

### Ref の適用範囲
- 同一スタック内のリソース・パラメータを参照するもの
- スタック間参照はできない（その場合は Export + ImportValue を使う）

---

# SCP (Service Control Policy)

## デフォルトのSCP

すべてのOUやアカウントに最初からアタッチされているのは FullAWSAccess というSCP

### 内容
「全サービス・全アクションを許可」

つまり最初の状態では「SCPによる制限は何もかかっていない」

---

## IAMポリシーのデフォルト挙動

### 基本原則
IAMユーザー/ロールは、明示的に許可を与えない限りすべて拒否（Deny）

つまり「デフォルトはフル拒否」

ポリシーをアタッチしないと何もできない

---

## SCPのデフォルト挙動

### 初期状態
AWS Organizations では、最初から全OU/アカウントに FullAWSAccess というSCPがついている

### 内容
「Effect: Allow 全サービス・全アクション」

つまり「制限がかかっていない状態」

これがあるから SCPにより拒否はされない（IAM次第になる）

---

# CloudFront 価格クラスの実例

## 東京のユーザーがサイトにアクセスした場合

### Price Class All
東京のエッジロケーションから配信（超速い⚡️）

### Price Class 100
東京は含まれないので、たとえばシンガポールや米国西海岸のエッジから配信 → レイテンシー増加

## 影響

価格クラスを制限すると「その地域のエッジが使えず、距離的に遠いロケーションから配信される」ため速度に影響が出る

SSH(22) のとき

目的: 管理者がサーバーにログインするため

経路: 社内PC → 踏み台サーバー(22) → アプリサーバー(22)

だから「22番ポートを開ける」のが正解

この通信は 管理用トラフィック

🔹 HTTP/HTTPS(80/443) のとき

目的: エンドユーザーがWebアプリを使うため

経路: インターネットユーザー → ALB(80/443) → アプリサーバー(80/443)

だからアプリサーバーは ALB経由の80/443 を開ける必要がある

この通信は アプリケーションのサービス用トラフィック

🔹 なぜ22じゃないのか？

22番は サーバー管理のためのSSH専用

一般ユーザーはSSHしません。

Webユーザーは HTTP(80) / HTTPS(443) を使ってアクセスするから、そのポートを開ける必要がある

ポート番号と使い道

22番 (SSH)

サーバー管理用

運用者がサーバーにログインするときに使う（踏み台経由など）

エンドユーザーは使わない

80番 (HTTP)

Webサイトを暗号化せずに公開するときの標準ポート

例: http://example.com

443番 (HTTPS)

WebサイトをTLS/SSLで暗号化して公開するときの標準ポート

例: https://example.com

セキュリティグループで指定できる項目

IPアドレス / CIDR ブロック

例: 203.0.113.25/32（単一IP）

例: 203.0.113.0/24（サブネット範囲）

インターネットやオンプレの固定IPとの通信制御に使う

他のセキュリティグループ

同じVPC内のSGを指定できる

「踏み台SGからだけ許可」や「ALB-SGからだけ許可」みたいに柔軟に設定できる

インスタンス数が増えてもIPを直書きしなくていいので管理が楽

プレフィックスリスト (Prefix List, PL)

AWSが管理する or ユーザーが作成する 一連のCIDRのまとまり

例: S3エンドポイント用のプレフィックスリスト → これを指定すればS3通信をまとめて許可できる

大規模環境で便利

ネットワークACL (NACL) で指定できる項目

NACLは サブネット単位 のステートレスなファイアウォール。ルールの構成要素はシンプルです👇

ルール番号 (Rule #)

優先度を決めるための番号（小さい方が優先）

例: 100, 200, 300 …

トラフィック方向

インバウンド / アウトバウンド

プロトコル

TCP / UDP / ICMP / ALL

ポート範囲

例: TCP 22, TCP 80-443, ALL

ソース / 宛先

CIDR ブロックのみ（例: 0.0.0.0/0, 10.0.0.0/16, 203.0.113.25/32）

アクション

ALLOW（許可）

DENY（拒否）

セキュリティグループとの違い
項目	セキュリティグループ (SG)	ネットワークACL (NACL)
適用単位	インスタンス	サブネット
指定できるもの	CIDR / SG / プレフィックスリスト	CIDRのみ
状態管理	ステートフル（戻り通信は自動許可）	ステートレス（戻り通信もルール必要）
アクション	ALLOWのみ	ALLOW / DENY 両方

Lambda 実行ロール (Execution Role)

Lambda が動くときに 「この関数はどんなAWSリソースにアクセスできるか」 を定義する IAM ロール

例えば：

S3 からデータを読みたい → s3:GetObject

DynamoDB に書き込みたい → dynamodb:PutItem

CloudWatch Logs にログを出す → logs:CreateLogStream と logs:PutLogEvents

Lambda を作成するときに「IAMロールをアタッチ」する画面があるけど、それがこれ

👉 実行ロールがないと、Lambda は AWS の他リソースに一切アクセスできない。

Lambdaに関わる権限は大きく分けて2種類あります。

IAMロール (実行ロール, Execution Role)

「Lambda関数が AWSリソースにアクセスする権限」を持つ

例: S3からデータを読む、DynamoDBに書く、CloudWatch Logsに出力する

リソースベースポリシー (Resource-based Policy)

「誰（どのサービスやアカウント）が このLambdaを呼び出せるか」を定義する

EventBridge → Lambda を呼び出す場合はここに書く必要あり


目	IAMロール (実行ロール)	リソースベースポリシー
権限の方向性	「Lambda が何をできるか」	「誰が Lambda を呼べるか」
適用対象	Lambda の実行環境	Lambda 関数そのもの
主な用途	Lambda → S3, DynamoDB, CloudWatch など	EventBridge, S3, API Gateway → Lambda

eventbridgeからlambda呼ぶならlambdaにリソースベースポリシーつけるlambdaからs3なら実行ロールをつける

IAMポリシーが付く場所は大きく2種類

IAMロール（実行ロール）

Lambda関数やEC2など「AWSリソースが他のサービスにアクセスするとき」に使う

Lambdaの場合 → LambdaがS3やDynamoDBを操作するために必要

＝「呼び出す側」に付ける

リソースベースポリシー

S3バケットやLambda関数など「呼び出されるリソース」に直接アタッチできるポリシー

例えば Lambda に設定すると「誰（どのサービス/アカウント）がこのLambdaを呼べるか」を制御

＝「呼び出される側」に付ける

🔹 まとめると

IAMロール (実行ロール) → 呼び出すリソースに付ける（Lambda → S3, EC2 → DynamoDB など）

リソースベースポリシー → 呼び出されるリソースに付ける（EventBridge → Lambda, S3 → Lambda など）

DynamoDB のポイントインタイムリカバリ

特徴

復元できる範囲

有効化してからの 最大35日間 の任意の時刻に復元可能

秒単位で指定できる

「昨日の13:05:23の状態に戻したい」といったことができる

バックアップの方式

DynamoDB が自動で継続的にバックアップを取る

ユーザーが明示的にスナップショットを作らなくてもOK

復元の挙動

復元先は 新しいテーブル として作成される

元のテーブルが上書きされるわけではないので安全

デフォルトでは無効

明示的に有効化しないと使えない（有効化後からのデータしか対象にならない）

🔹 ユースケース

アプリのバグや誤操作でテーブルが壊れた／削除されたときに、直前の状態まで戻す

「1時間前の状態を再現してデバッグしたい」といった調査用途

長期的なバックアップ管理より「事故リカバリ用」に便利

---

## DynamoDB バックアップ戦略

### RPO・RTO 要件

#### RPO（復旧可能なデータの古さの目標）= 15分
データ損失は最大15分まで許容

#### RTO（復旧時間の目標）= 1時間
障害から1時間以内にアプリ復旧が必要

---

## DynamoDBの選択肢

### オンデマンドバックアップ
- 明示的に作成するスナップショット
- RPOはバックアップ取得時点
- 毎15分で手動 or Lambdaで自動化すればギリ対応可能だが、RPO=15分を保証するのは難しい

### ポイントインタイムリカバリ (PITR)
- 有効化しておけば、最大35日前まで、任意の秒単位で復元可能
- RPO は数秒～数分レベルで達成可能（15分より十分良い）
- 復元は新しいテーブルとして作られるので安全
- 復旧作業も比較的早く行えるため、RTO=1時間以内も現実的

### グローバルテーブル
- 複数リージョンに自動レプリケーション
- リージョン障害に備えたDR向け
- 今回は「DB障害からの復旧」であり、マルチリージョン必須とは書かれていない

---

## PITR が有効なときに災害が起きた場合

### 基本機能
DynamoDB PITR を有効化しておけば、有効化以降の全ての変更履歴を最大35日間保持

災害やアプリケーションのバグでデータが壊れたり消えたりしても、任意の秒単位の時点にテーブルを復元できる

### 例
- 誤って顧客データを削除した → 直前の状態に復元可能
- アプリのバグでデータが壊れた → バグが発生する直前の時点まで戻せる

### 復元の方法
PITRで復元するときは、既存のテーブルを上書きせず、新しいテーブルを作成

復旧後はアプリケーションをその新しいテーブルに切り替えればOK

### 制約
- PITRを有効にする前のデータには戻せない（有効化してからが対象）
- 復元はリージョン内限定（リージョンが落ちた場合はPITRだけでは不十分 → その場合はグローバルテーブルを検討）

---

## セキュリティグループの補足

正確にいうと、セキュリティグループは EC2 インスタンスそのものにつくのではなく、ENI（Elastic Network Interface）にアタッチされている

---

# AWS DataSync

## 概要

AWS DataSync は データ転送・移行専用サービス

---

## 対応する転送パターン

### 1. オンプレミス ↔ AWS
- オンプレのストレージ（NFS、SMB、HDFS など）から AWS へ
- AWS からオンプレへ（双方向）
- よくあるユースケース：オンプレ NAS → Amazon S3 / EFS / FSx

### 2. AWS ↔ AWS
- S3 バケット間（別リージョンもOK）
- EFS → EFS
- FSx → FSx
- S3 ↔ EFS / FSx

AWS 内のサービス間でも DataSync を使うと 差分コピー、帯域制御、暗号化、監査ログ が自動で管理されるので便利

---

## 特徴

- 差分コピー（変更分のみ同期可能）
- スケジューリング（定期的な転送）
- 帯域制御（オンプレ回線を圧迫しないよう調整可能）
- 転送時暗号化 + データ整合性チェック

---

## DataSync エージェントが必要かどうか

結論から言うと、接続元がオンプレか、AWSサービスかで変わる

### エージェントが必須のケース

#### オンプレミスのストレージ → AWS
- NFS サーバー、SMB サーバー、HDFS など
- VMware/Hyper-V/KVM 上の VM でエージェントをデプロイする必要がある
- これがオンプレと AWS をつなぐ役割

### エージェントが不要なケース

#### AWS サービス間の転送
- 例: S3 ↔ S3、S3 ↔ EFS、S3 ↔ FSx、EFS ↔ FSx
- これらは DataSync がマネージドで直接やり取りするので エージェント不要

---

## まとめ

- オンプレ → AWS = エージェント必須
- AWS ↔ AWS = エージェント不要

---

# Redshift vs EMR ログ解析比較

## Redshift の場合

### 得意分野
- データウェアハウス (DWH) として構造化データの集計や BI ツールとの連携に強い
- 既に整形済みのデータをロードして、長期的に傾向分析するのに最適

### 弱点
- ログのような「非構造化または半構造化データ」をそのまま扱うのは苦手
- ロード (COPY コマンドなどで S3 → Redshift) に手間がかかり、リアルタイム性が低い

---

## EMR の場合

### 得意分野
- Apache Hadoop / Spark クラスタで動くため、大量のログファイルを直接処理可能
- JSON / CSV / 未加工ログなども柔軟に解析できる
- スケールアウト可能で「膨大なログを並列解析」するのに向いている

### 弱点
- Redshift より運用の手間がかかる（クラスタ管理やジョブ設計が必要）
- BI ツールとの統合は Redshift ほど簡単ではない

Redshift だと一度スキーマ定義 & データロードが必要なので、ログ解析の一次用途にはオーバーヘッドが大きい

---

## Redshift とスキーマ

Redshift は RDBMS 系のデータウェアハウス なので、スキーマ定義（テーブル構造） が必須

### ログを Redshift に入れる場合の手順

1. まず S3 にログを集約
2. テーブルを定義（DDL で CREATE TABLE）
   - カラム名、データ型、DISTKEY/SORTKEY などを指定
3. COPY コマンドでロード
   - S3 → Redshift にデータ取り込み
4. その後に SQL でクエリ実行

---

## サービス別特徴まとめ

- **Redshift** → 構造化されたデータを高速に集計・BI で活用
- **Athena** → S3 上のログを 外部テーブル定義で直接クエリ可能（データロード不要）
- **EMR** → 生ログを Hadoop/Spark で直接解析

---

# ALB のリスナー

## 概要

リスナー (Listener) = ALB が受け付ける ポート と プロトコル を定義するもの

例えば「HTTP (80)」や「HTTPS (443)」など

受け付けたリクエストに対して、ルールに基づきどのターゲットグループに転送するかを決定

---

## プロトコルとポート

- HTTP (80)
- HTTPS (443)

HTTPS を選んだ場合は SSL証明書（ACMやIAMで管理）を設定可能

---

## ルール (Listener rules)

リクエストの内容に応じてアクションを設定できる。主な条件とアクションは以下：

### 条件（Condition）

- Hostヘッダー（例: api.example.com なら API 用ターゲットにルーティング）
- Pathパターン（例: /images/* なら画像用ターゲットにルーティング）
- HTTPヘッダー（特定のヘッダー値で分岐）
- HTTPリクエストメソッド（GET, POST など）
- Query string（例: ?env=dev なら開発環境にルーティング）
- Source IP（特定のクライアントIP範囲からのアクセスをルーティング）

### アクション（Action）

- ターゲットグループに転送（通常の使い方）
- 固定レスポンスを返す（例: 403 Forbidden を即時返す）
- リダイレクト（HTTP → HTTPS へのリダイレクトなど）
- 認証（Cognito や OIDC を使った認証）

---

# マルチバリュー回答ルーティング

## 概要

Route 53 が 1つのDNSクエリに対して複数のレコード（最大8個）を返す仕組み

返すレコードはすべて ヘルスチェック連携可能

つまり「複数サーバーの中から、正常なものだけを最大8個まとめて返す」動きをする

---

## 特徴

### ラウンドロビン的に分散
返された複数IPの中から、クライアント（OSやブラウザ）がどれを使うかを決定する

### ヘルスチェック対応
ヘルスチェックに失敗したIPは返さない

### シンプルな冗長性確保
ELB を使わずに、簡易的な可用性を担保できる

---

## 他ルーティングポリシーとの違い

- **単純ラウンドロビン** → ヘルスチェックできない（死んでるサーバーも返す） 単純ラウンドロビン = シンプルルーティング
- **加重ルーティング** → 重み付け制御ができるが、複数値回答のようにまとめて返すのが目的ではない
- **フェイルオーバー** → 主系/副系を切り替える用途
- **マルチバリュー回答** → 「複数の生きてるIPを返す」シンプル設計

---

## ユースケース

- シンプルなWebサービスで、ロードバランサーを使わずに 複数のEC2に直接トラフィックを分散させたいとき
- DNSレベルでの「簡易ロードバランシング + ヘルスチェック」

Route 53 フェイルオーバールーティングの仕組み

Route 53 が自前のヘルスチェック機能を使って、リソースの正常性を監視します。

ヘルスチェックの結果に基づいて、DNS クエリに返すレコードを切り替えます。

主系（Primary）がダウンしたら副系（Secondary）に切り替える ― これが「フェイルオーバー」。

OAC (Origin Access Control) とは

OAI (Origin Access Identity) の後継となる仕組み

CloudFront と S3 の間の通信を 署名付きリクエスト（SigV4署名） によってセキュアに行う

直接S3にアクセスできないようにして、必ずCloudFrontを経由させるために使う

従来の OAI との違い
項目	OAI (従来)	OAC (新しい方式)
認証方式	CloudFront 用の IAM ユーザー的な仕組み	SigV4 署名リクエスト
暗号化	サポート弱い	SSE-KMS, SSE-S3 など強化
適用範囲	S3 のみ	S3 以外のオリジンも将来的に対応予定
推奨度	既存環境では使える	新規は OAC推奨

OAC を使わない場合

CloudFront のオリジンに S3 バケットを指定するだけでも配信は可能です。

ただしその場合は、S3 側を以下のどちらかにしておかないといけません：

バケットをパブリックアクセス許可（危険 ⚠️）

署名付きURL / 署名付きCookie を使う（ただし直アクセスを完全には防げない）

つまり「配信自体はできるけどセキュリティ的に甘い」状態になります。

OAC を使うメリット

S3 を非公開のままにできる

CloudFront からのアクセスだけを許可できる

ユーザーが直接 S3 バケットの URL (https://s3.ap-northeast-1.amazonaws.com/bucket/...) にアクセスしてもブロックされる

静的ウェブサイト + OAC の考え方

S3 の 静的ウェブサイトホスティング機能をそのまま使う場合は、バケットを パブリック公開する必要があります。

でもセキュリティ的には「S3 直アクセスはさせたくない、CloudFront 経由だけで配信したい」というのがベストプラクティス。

そこで CloudFront + OAC を組み合わせると、

S3 は非公開（パブリックアクセス無効）

CloudFront が OAC を使って署名付きリクエストを発行し、S3 からオブジェクト取得

ユーザーは必ず CloudFront 経由でアクセス

これにより 静的Webサイトをセキュアにホストできる

---

## OAC は静的Webサイトホスティングに使える

実際には「S3 静的サイトホスティング」機能を直接使うのではなく、CloudFront + OAC + 非公開S3で安全に公開する構成が推奨

OACを使う目的 = 「S3を非公開にして、CloudFront経由のリクエストだけを許可」すること

---

# Auto Scaling クールダウン設定

## 1. クールダウン期間（Cooldown Period）

### 概要
スケールアウト／スケールインの両方に影響する共通設定

### 仕組み
- スケーリングアクションが起きた直後に「ちょっと待って様子見しよう」という時間
- デフォルトは 300 秒（5分）
- この間は新しいスケーリングアクションを実行しない

---

## 2. スケールイン保護（Scale-In Protection）

### 概要
個々のインスタンスに「スケールインで終了対象にならないようにする」設定

これは「クールダウン」ではなく「除外ルール」に近い

---

## 3. スケールインのクールダウン（Scale-In Cooldown）

### 概要
ターゲット追跡スケーリングポリシー（Target Tracking Scaling Policy）を使う場合、「スケールアウトのクールダウン」とは別に スケールインのクールダウン期間 を個別に設定できる

### 目的
「スケールインはちょっと慎重にやりたい」ときに使う

（一気に縮退すると可用性に影響する可能性があるため）

---

# Auto Scaling メトリクス詳細

## 各メトリクスの意味

### 1. ASGAverageCPUUtilization

Auto Scaling グループに属する 全インスタンスの CPU 使用率を平均した値

#### 例
- インスタンスA：40%
- インスタンスB：20%
- → ASGAverageCPUUtilization = (40 + 20) / 2 = 30%

### 2. ASGAverageNetworkIn

グループ内の全インスタンスで受信した バイト数を平均

インスタンスごとの受信量を合計して、インスタンス数で割ったもの

### 3. ASGAverageNetworkOut

上と逆で「送信した平均バイト数」

### 4. ALBRequestCountPerTarget

ALB のターゲットグループに登録された 1ターゲットあたりの平均リクエスト数

#### 例
- ALB → インスタンスA: 100リクエスト, インスタンスB: 200リクエスト
- ターゲット数 = 2
- → ALBRequestCountPerTarget = (100 + 200) ÷ 2 = 150

---

## RequestCountPerTarget 詳細

### 基本情報
- 正式名：ALBRequestCountPerTarget
- 意味：ALB のターゲットグループ内で、1ターゲットあたりが処理したリクエスト数
- 単位：リクエスト/秒（Average）

### 動きのイメージ

#### 例：ALB → ターゲットグループに EC2 インスタンスが 2 台登録されている場合
- インスタンスA: 200 リクエスト/秒
- インスタンスB: 100 リクエスト/秒
- ターゲット数 = 2
- → RequestCountPerTarget = (200 + 100) ÷ 2 = 150 リクエスト/秒

### ユースケース

- ターゲットごとにリクエスト数がどれくらい処理されているかを基準にスケーリングしたいときに使う
- 例えば「1台あたり 1000 リクエスト/秒を超えたらスケールアウト」などの設定が可能
- CPU や NetworkIn/Out だとアプリケーション負荷を直接反映しにくい場合に有効

---

# AWS DataSync で移行できるもの

## 移行できるもの

### 1. オンプレのファイルシステムから AWS へ

- NFS（Linux 系のNAS、ファイルサーバー）
- SMB（Windows 系のファイルサーバー、NAS）
- HDFS（Hadoop 分散ファイルシステム）

典型例：オンプレ NAS → S3 / EFS / FSx for Windows

---

## DataSync の制限事項

AWS DataSync はネイティブに SFTP をサポートしていない

対応しているのは NFS, SMB, HDFS, AWS Storage サービス（S3/EFS/FSx）

---

## SFTP データを AWS に移行する方法

### 1. AWS Transfer Family (Managed SFTP)

- AWS が提供する マネージド SFTP サービス
- オリジンとして S3 または EFS を指定できる
- 既存のオンプレ SFTP クライアントからそのまま使える
- 移行後も SFTP を使い続けたいなら最適

SFTPを扱うなら AWS Transfer Family を使うのがベスト

---

# AWS Transfer Family

## 概要

AWS が提供する「ファイル転送プロトコルをマネージドで使えるサービス群」の総称

## 構成員（ファミリーの一員）

- AWS Transfer for SFTP（SSHベースの安全なファイル転送）
- AWS Transfer for FTPS（FTP over SSL/TLS）
- AWS Transfer for FTP（通常のFTP、レガシー互換）
- AWS Transfer for AS2（EDIで使う業界標準プロトコル）

---

# SFTP とは

## 基本情報

- 正式名称：SSH File Transfer Protocol または Secure File Transfer Protocol
- SSH（Secure Shell）をベースにした ファイル転送用のプロトコル
- FTP（File Transfer Protocol）と混同されやすいけど、全く別モノ

## 特徴

- 通信はすべて暗号化（ユーザー認証・コマンド・データ転送）
- 単一のポート（通常 22）で動作 → ファイアウォール越えも比較的容易
- SSHの仕組みを流用するので、公開鍵認証・パスワード認証などが使える
- 機能はファイルアップロード、ダウンロード、削除、リネーム、ディレクトリ操作など

---

## FTP / FTPS との違い

- **FTP**：暗号化なし、ポート21＋データチャネル（20や動的ポート）を利用
- **FTPS**：FTP + SSL/TLS で暗号化
- **SFTP**：SSHベース、完全に別プロトコル、暗号化が標準

AWS で「SFTPサーバーを使いたい」ときは AWS Transfer Family がベスト

SFTP = SSH を使った安全なファイル転送プロトコル

---

# DMS と SCT の役割分担

## 1. AWS DMS (Database Migration Service)

### 役割
データの移行を担当

### 機能
- レコードやテーブルの中身（スキーマ内のデータ）をコピーする
- 同種DB (MySQL→MySQL) でも異種DB (Oracle→Aurora) でもOK
- 継続的な変更同期 (CDC: Change Data Capture) も可能

---

## 2. AWS SCT (Schema Conversion Tool)

### 役割
スキーマやコードの変換を担当

### 変換例
- Oracle の PL/SQL → PostgreSQL の PL/pgSQL に変換
- データ型の変換 (NUMBER → NUMERIC, DATE → TIMESTAMP など)
- ストアドプロシージャ、ビュー、トリガー、関数の変換

### 特徴
自動変換できない部分はレポート化して「ここは手で直してね」と教えてくれる

---

## よくある使い方（組み合わせ）

異種DB間の移行 (heterogeneous migration) のときによくセットで使う

### 手順
1. SCT でスキーマ変換 & ターゲットDBに適用
2. DMS でデータを移行（＋必要ならCDCで差分同期）

この流れなら スキーマとデータの両方を正しく移行できる

---

# CloudFront 価格クラスの種類

## Price Class 100

### 特徴
- 最も安い
- 米国・カナダ・欧州の一部リージョンのみ

## Price Class 200

### 特徴
- 中間
- Price Class 100 ＋ 一部のアジア・中東

## Price Class All

### 特徴
- 最も高い
- 全世界の CloudFront エッジロケーションを利用

---

## 価格クラスの選択指針

高いほど多くのリージョンで配信されるので、グローバルユーザーにとっては速くなる可能性がある

でも 必ずしも高い＝速い ではなく、ユーザーの分布次第

---

# SQS 複数キューでの優先度制御

## 概要

複数キューを作って、それを優先度付きのように扱う

## 構成例

### キュー設定
- 有料ユーザー用 → HighPriorityQueue
- 無料ユーザー用 → StandardQueue

### 処理ロジック側で
1. HighPriorityQueue を優先的にポーリングする
2. 空なら StandardQueue を処理する

---

# DNS レコードタイプ

## エイリアスレコード
- **Aレコード**：IPv4
- **AAAAレコード**：IPv6
- **MXレコード**：メールサーバーを紐づける
- **CNAME**：ドメインを別のドメイン名に紐づける

---

# Trusted Advisor

---

# SSH 接続のときの流れ

## 自分のPC

サーバーに接続するときに、OS が一時的に「送信元ポート」を勝手に選ぶ

これが エフェメラルポート

### 例
50032 とか 60412 とか

## EC2（サーバー）

常に 22番ポート（SSH）で待ち受け

「クライアントIP:50032 → EC2IP:22」という形でリクエストを受け取る

## 戻りの応答

サーバーからは「送信元 22番 → 宛先 クライアントの50032番」へレスポンスを返す

なので、クライアント側のエフェメラルポートが開いてないと通信が成立しない

---

# ネットワークACL (NACL)

## 基本特性

### ステートレス
Inbound/Outboundを 両方明示的に許可しないと通信できない

「行きのリクエストは届くけど、戻りがNACLでブロックされて返ってこない」状態になる

---

## NACLの挙動整理

### デフォルトNACL
- Inbound / Outbound ともに すべて許可 (Allow All)
- だから特に何もしなくても通信できる

### カスタムNACL
- Inbound / Outbound のルールを自分で書く必要がある
- ステートレスなので 行きと戻りを両方許可しないと通信不可
- つまり「Inboundだけ許可してもNG」

---

## NACLは「両方向セットで許可」が基本

### ステートレスだから

- **Inboundだけ許可** → 行きは届くけど戻りがブロックされて通信不可
- **Outboundだけ許可** → 戻りは出せても、そもそも行きが入ってこないから通信不可

どちらか片方だけの設定では通信は成立しない

---

# RDS のストレージタイプ

## 概要

RDSを作成するとき、ストレージタイプを選べる

---

## 汎用SSD (gp2/gp3)

### 特徴
- コスパ重視
- IOPSは自動でスケールするけど、ピーク性能は限界あり

### 適用場面
一般的なWebアプリや小中規模DBに向く

---

## プロビジョンド IOPS (io1/io2)

### 特徴
- IOPSをユーザーが指定（最大256,000 IOPSまで ※DBエンジンによる）
- 高スループット & 安定性能

### 適用場面
OLTPシステム、大規模DB、金融系などI/Oレイテンシに敏感なワークロード向き

---

## マグネティック (HDD, 非推奨)

昔のHDDベース。新規はほぼ使わない

---

## まとめ

RDSのストレージタイプ選択 = EBSボリュームタイプの選択