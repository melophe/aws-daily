# Kinesis Data Streams から流せるサービス（Consumer）

## AWS Lambda

代表的な Consumer

Data Streams に新しいデータが入ると自動で Lambda を起動

サーバレスでイベントドリブン処理に最適

## Kinesis Data Firehose

Data Streams → Firehose → S3/Redshift/OpenSearch/HTTP Endpoint に配送

「Data Streamsをバッファして最終保存先に送る」用途でよく使用

## Amazon Kinesis Data Analytics（※今は "Managed Service for Apache Flink" に統合）

Data Streams に流れたデータに対して SQL / Flink を使ってリアルタイム分析

「1分間の平均値」などを算出して、結果を別の Kinesis Stream や Firehose に送信可能

## Amazon EC2 / ECS / EKS アプリ

SDK や Kinesis Client Library (KCL) を使って Consumer を作成

複雑な独自処理が必要なときに選択

## Amazon OpenSearch Service（間接的に Firehose 経由）

Firehoseを挟んで検索可能な形で取り込み

## 外部システム（HTTPエンドポイントなど、Firehose経由で送信可能）

## Data Streams が直接できないこと

- S3 に直接保存（Firehose経由ならOK）
- RDS/DynamoDBに直接保存（Lambdaなどの中継が必要）

---

# Redshift 暗号化

## 1. AWS KMS を利用して暗号化を実施

Redshift はデフォルトで KMS を使った暗号化に対応

KMS の CMK を使えば SSE (Server-Side Encryption) を実現

業界標準の HSM も裏側では KMS が管理しているので、要件の「暗号化」部分を満たす

## 2. Amazon Redshift と CloudHSM との間で信頼された接続を設定

CloudHSM を Redshift に接続すれば、自社専用の HSM を利用可能

これにより「業界水準に対応した暗号キー管理」を満たす

## 正しい組み合わせ

- AWS KMS を利用した暗号化
- Redshift と CloudHSM の接続

---

# RDS オートスケーリング比較

## RDS（MySQL / PostgreSQL / etc）

自動スケーリング機能なし

リードレプリカは自分で作成・削除する必要

自動化したければ CloudWatch Alarm + Lambda でスクリプトを組むような「自作オートスケーリング」が必要

## Aurora（Provisioned）

Aurora Auto Scaling あり

リードレプリカ（Reader インスタンス）を自動で増減

CloudWatch メトリクス（CPU使用率・接続数・レイテンシ）を監視して調整

書き込みノード（Writer）は 1 台固定（※Aurora Multi-Master は例外）

## Aurora（Serverless v2）

さらに柔軟なオートスケーリング

Aurora Capacity Unit (ACU) を秒単位で自動調整

インスタンス数という概念すら意識不要