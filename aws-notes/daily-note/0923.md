# プレイスメントグループ

## 目的

複数EC2インスタンスの配置を制御して、通信レイテンシ、スループット、耐障害性を調整する仕組み

## 種類と特徴

### 1. Cluster Placement Group（クラスタ配置）

同一AZの物理的に近いハードウェアに配置

#### メリット
- 超低レイテンシ
- 高スループット（10Gbps〜100Gbps級のノード間通信）

#### ユースケース
- HPC（ハイパフォーマンスコンピューティング）
- 分散ビッグデータ処理（Hadoop, Spark）
- EBS Multi-Attachと組み合わせるケース

### 2. Partition Placement Group（パーティション配置）

インスタンス群を「パーティション」に分け、異なるラックに配置

1パーティション内のインスタンスは同じラック

パーティション間ではラックが分離されるのでハード障害の影響を限定

#### メリット
- 数百〜数千台規模でも展開可能
- ラック障害耐性あり

#### ユースケース
- 大規模分散データベース（HDFS, Cassandra, Kafka など）
- ノード数が多いシステム

### 3. Spread Placement Group（スプレッド配置）

インスタンスをできるだけ物理的に分散

異なるハードウェア / ラックに分ける

#### メリット
- 単一障害のリスクを最小化
- 最大7インスタンス / AZ

#### ユースケース
- 高可用性が最重要な少数のインスタンス
- 例: 複数の重要アプリケーションサーバーを分散配置

## 比較表

| 種類 | 配置 | メリット | 制約/特徴 | 主な用途 |
|------|------|----------|-----------|----------|
| Cluster | 同一AZ、物理的に近接 | 超低レイテンシ / 高スループット | AZ限定、障害時に全滅リスク | HPC、ビッグデータ、低レイテンシ通信 |
| Partition | ラック単位で分離 | ラック障害の影響限定 / 大規模展開可能 | パーティション数制限あり | Cassandra, Kafka, HDFS |
| Spread | 最大限分散配置 | 高可用性 / 単一障害回避 | 1 AZあたり7台まで | 少数の重要インスタンス |

---

# EBS Multi-Attach

## 通常のEBS

1つのEBSボリューム = 1つのEC2インスタンスにアタッチ

複数のインスタンスに同時接続はできない（データ整合性が崩れるため）

## 特例: EBS Multi-Attach (io1/io2限定)

Provisioned IOPS SSD (io1, io2) ボリュームのみ対応

1つのEBSボリュームを同一AZ内で最大16台のEC2インスタンスに同時接続可能

ただし、複数インスタンスで同じブロックデバイスを同時に読み書きするため、アプリケーション側での排他制御が必須

## ユースケース

- クラスター型のアプリケーション
- 例: データベースクラスタ、HPC、ゲノム解析クラスター
- 複数ノードが同じデータにアクセスする必要がある場合

→ このときに Cluster Placement Group と組み合わせると、低レイテンシかつ高スループットで効率的に動作

---

# Aurora の DR 機能

## 1. マルチAZ構成（自動的に有効）

Aurora クラスターはデフォルトで マルチAZ冗長

データは 6コピー（3つのAZに2コピーずつ） に分散して保存

1つのAZやディスクに障害があっても、自動的に別AZから継続可能

これは 高可用性 (HA) 対策に近い

## 2. Aurora リードレプリカ

同じリージョン内でリードレプリカを最大15台追加可能

Writer（プライマリ）障害時、レプリカを昇格させてフェイルオーバー可能

これもDRというより 可用性・読み取りスケール対策

## 3. クロスリージョンレプリカ (Aurora Global Database)

データをリージョン間で非同期レプリケーション

1秒未満のレイテンシーで別リージョンに複製

リージョン全体が落ちても、セカンダリリージョンで迅速にフェイルオーバー可能

典型的な DR構成

## 4. バックアップとスナップショット

自動バックアップ: 最大35日間の PITR（ポイントインタイムリカバリ）が可能

手動スナップショット: 永続保持、他リージョンへコピー可能

これは長期保存 & 復旧の仕組み（RTO/RPOがやや大きめ）

## まとめ（AuroraのDRパターン）

| DR手段 | RPO | RTO | コスト | 用途 |
|--------|-----|-----|--------|------|
| マルチAZ冗長（標準） | ほぼゼロ | 数秒～分 | 標準料金内 | AZ障害対策 |
| リードレプリカ昇格 | 数秒～分 | 数分 | レプリカ台数分 | Writer障害 |
| Global Database | <1秒 | 分単位 | 高い | リージョン障害対策 |
| バックアップ/スナップショット | 最大35日 | 数時間～日 | 安い | 長期保存・手動復旧 |

---

# RPO / RTO

## RPO (Recovery Point Objective)

日本語: 目標復旧時点

災害や障害が起きたとき、どの時点までのデータを復旧できるかを示す

「データ損失の許容範囲」を表す

### 例
RPO = 5分 → 障害が発生しても 直近5分以内のデータ損失は許容

バックアップ頻度やレプリケーション方式に依存

## RTO (Recovery Time Objective)

日本語: 目標復旧時間

災害や障害後、システムをどのくらいの時間で復旧できるかを示す

「停止時間の許容範囲」を表す

### 例
RTO = 1時間 → 障害が起きても 1時間以内にシステムを復旧する必要

フェイルオーバーの自動化・DR手順の設計に依存

## まとめイメージ

| 項目 | 意味 | 観点 |
|------|------|------|
| RPO | どこまでデータを守れるか | データ損失 |
| RTO | どれだけ早く復旧できるか | 停止時間 |

---

# AWS Snow Family

オンプレやエッジ環境から大量データをAWSに移行するための物理デバイス群をまとめて Snow Family と呼ぶ

## 主なサービス

### AWS Snowcone

- 最小・最軽量（約2.1kg）
- 容量：8TB HDD / 14TB SSD
- 特徴：小型、持ち運び可能、ドローンや小規模拠点でも使用可能

### AWS Snowball Edge

- 大型・堅牢（数10TB～数100TB）
- 「Storage Optimized」や「Compute Optimized」モデルあり
- コンピューティング機能（EC2インスタンスを動かせる）付き

### AWS Snowmobile

- 超大型（1台のトレーラーで100PB）
- データセンター単位で大規模移行したいときに利用