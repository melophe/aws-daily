# AWS Outposts

## 概要
AWSサービスをオンプレミス環境に展開可能

## メリット
- EMRをOutpostsに展開すれば、オンプレのデータに低遅延アクセス可能
- クラウドの管理性・スケーラビリティを保持

---

# ファイル共有プロトコル

## 1. NFS (Network File System)

### 概要
UNIX/Linux系でよく使われるファイル共有プロトコル

### 特徴
- ネットワーク越しにファイルをローカルディスクのように扱える
- サーバー・クライアント方式（NFSサーバーを立て、クライアントがマウント）

### ユースケース
- Linuxサーバー同士でのファイル共有
- NASストレージとの接続

## 2. SMB (Server Message Block)

### 概要
Windows系でよく使われるファイル共有プロトコル

### 別名
CIFS (Common Internet File System)

### 特徴
- Windowsエクスプローラーで「共有フォルダ」として表示される
- 認証やアクセス制御にActive Directoryとの統合が可能

### ユースケース
- Windows環境でのファイルサーバー共有
- MacもSMBを使用可能（最近はNFSよりSMBの方が一般的）

## 3. HDFS (Hadoop Distributed File System)

### 概要
Apache Hadoop向けの分散ファイルシステム

### 特徴
- 大容量データを複数のサーバーに分散保存
- データはブロック単位（通常128MB）で分割し、複数のサーバーに冗長保存
- 「データを動かすより計算を動かす」思想（MapReduceやSparkと連携）

### ユースケース
- ビッグデータ処理（Hadoop, Spark, Hiveのストレージ層）
- 解析基盤のストレージとして利用

---

# CloudFormation

## CloudFormationでできること

### インフラ構築・管理
- サーバー・ネットワーク・DB・ロードバランサーなどの構築・管理
- 例: EC2、ALB、Auto Scaling Group、RDS、VPCサブネットなどをマルチAZに自動デプロイ

### 複数環境対応
- 複数環境（本番・ステージング）の構築を自動化
- パラメータを変えるだけで、同じ構成を別環境に複製可能

### 役割
CloudFormationは「Infrastructure as Code (IaC)」= インフラの定義・展開を担当

## CloudFormationでできないこと

### アプリケーション管理
- アプリケーションコードのデプロイや更新管理
- 例: WebアプリのソースコードをEC2に配置
- 例: ECS/EKSにコンテナイメージをデプロイ
- 例: デプロイ後にアプリを段階的に更新（Blue/Green, Canaryなど）

### 重要なポイント
アプリケーションのライフサイクル管理は別のサービスが必要

---

## Elastic BeanstalkとCloudFormationの関係

### Elastic Beanstalk (EB)の機能
- アプリケーション実行環境（EC2/ALB/Auto Scaling/RDSなど）を自動で構築＆管理
- 内部的にはCloudFormationを利用してインフラをデプロイ
- アプリケーションコードのデプロイ管理までサポート（CloudFormation単体との違い）

### 関係性
EB = CloudFormation + アプリケーション管理のラッパー

---

# SNSに直接publish可能なサービス

## 概要
AWSが公式にSNS連携のターゲットとして提供しているサービス

## 対象サービス
- **CloudWatch Alarms**: メトリクスしきい値通知
- **S3**: オブジェクト作成イベント → SNS
- **RDS**: イベント通知
- **CloudFormation**: スタック通知
- **Auto Scaling**: イベント通知
- **Elastic Beanstalk**: イベント通知

## 特徴
これらは「イベント発生 → そのままSNSトピックにpublish」が可能

---

# DynamoDB Auto Scaling

## 機能
- プロビジョンドモードの場合に利用可能
- CloudWatchメトリクスを監視して、RCU/WCUを自動的に増減
- EC2のASGに相当する「需要に応じた自動スケーリング」

## 例
テーブルの使用率が70%を超えたらRCUを増やす

## モード比較
- **プロビジョンド**: 最初にRCU/WCUを決めるが、Auto Scalingで動的調整可能
- **オンデマンド**: 完全に自動、最初の設定すら不要

---

# DynamoDB マルチAZ構成

## 概要
Amazon DynamoDBはフルマネージド & デフォルトでマルチAZ構成

## 特徴
- 同一リージョン内の複数のAZに自動的にデータを複製して保存
- ユーザー側が「マルチAZを有効にする」設定は不要

---

# DynamoDB DAX

## 制限
- DAXは一部のデータ（キャッシュヒットするデータ）に対してのみ効果あり
- テーブル全体に対する「スループット向上」や「WCU削減」にはならない

---

# RDB スケーリング戦略

## 読み取りスケーリング

### 基本手法
リードレプリカを追加して負荷分散

### 各サービスの制限
- **RDS**（MySQL, PostgreSQLなど）: 最大5台までリードレプリカを作成可能
- **Aurora**: リードレプリカ（読み取りノード）を15台まで追加可能

### 効果
読み込み専用のクエリを振り分ければ、読み取り性能はほぼ水平スケール可能

### まとめ
「読み取り = リードレプリカで横に増やす」

## 書き込みスケーリング

### 基本制限
- 書き込みはプライマリインスタンス（マスター）に集約される
- 基本的にはインスタンスタイプを変更して垂直スケール（スケールアップ/ダウン）するしかない
- AuroraだとWriterノードは1つ（※Aurora Multi-Masterはあるが制約が多く一般的ではない）

### まとめ
「書き込み = 垂直スケール（インスタンスタイプ変更）」

---

## 自動スケーリング機能比較

### Auroraの場合
- **Aurora Auto Scaling**機能を提供
- CloudWatchメトリクス（CPU使用率、接続数、レイテンシなど）に応じてリードレプリカの数を自動で増減可能
- 「CPUが上がったらリードレプリカ追加」が可能

### 通常のRDSの場合（MySQL/PostgreSQLなど）
- 手動でリードレプリカを作成するしかない
- 自動化したい場合はLambda + CloudWatch Alarmでトリガーを作ってリードレプリカを増やすスクリプトを動かす方法はあるが標準機能ではない
- 「削除」や「数の調整」はさらに手間がかかる

---

# RDS シャーディング

## 概要
RDSインスタンスを複数立ち上げて、それぞれにデータの一部を分散して保存する構成

## 構成例
```
RDS インスタンス A
→ ユーザーID 1〜100万のデータ

RDS インスタンス B
→ ユーザーID 100万1〜200万のデータ

RDS インスタンス C
→ ユーザーID 200万1〜300万のデータ
```

## 手法比較
- **リードレプリカ**: 読み取り性能スケールアウト
- **シャーディング**: 書き込み性能スケールアウト（複数インスタンスに分散）

## 重要なポイント
- シャーディング = プライマリが複数存在する構成
- 1つのプライマリだけではシャーディングにならない
- RDSの場合は「複数の独立したRDSインスタンスを並べる」イメージ

---

# Kinesis Data Streams vs API管理

## Kinesis Data Streamsの役割
- リアルタイムで大量のデータを取り込む・処理するためのサービス
- Producer（アプリ・デバイスなど）がデータをストリームに送信
- Consumer（Lambda、Kinesis Data Analytics、EC2など）が順次処理
- あくまで「データ取り込み基盤」であり、外部リクエストの制御やAPI管理機能は持たない

## Restful APIとして必要な機能
ベンダー向けにリクエストを受けるAPIを設計するとき必要な要件:
- APIリクエスト数の制御（Rate Limiting）
- 認証・認可（IAM / Cognito / APIキーなど）
- レスポンス制御（ステータスコード、エラー処理）
- SLAを守るためのスロットリング

### 重要なポイント
- これらはKinesis単体では実現不可能
- Kinesis Data Streamsだけでは「APIとしての機能（リクエスト制御・認証・スロットリング）」は実現できない
- 「ベンダー向けのリクエスト制御付きRestful API」を作りたいなら、API Gatewayなどのサービスと組み合わせが必要

---

# API Gateway + Lambda構成

## 構成例

### Amazon API Gateway
- Restful APIを公開
- 認証（IAM / Cognito / APIキー）を設定
- Usage Plan（使用量プラン）でサードパーティごとに「クォータ」や「スロットリング（1秒あたりのリクエスト数）」を制御可能
- 例: Vendor A → 1秒あたり10リクエストまで、1日1万リクエストまで

### AWS Lambda
- API Gatewayから呼び出されるバックエンド
- 実際の処理をサーバレスで実行（アプリロジック、データ保存、KinesisやDynamoDBへの書き込みなど）
- オートスケールするため、不定期アクセスやスパイクにも対応可能

### 外部（サードパーティアプリ）
- APIキーやCognitoなどの認証方式を使ってアクセス
- API Gatewayが「ベンダーごとの制御」を実施

## メリット
- **リクエスト制御**: Usage Planでベンダーごとに細かく制御可能
- **認証/認可**: APIキー, Cognito, IAM, Lambdaオーソライザーなど選択肢豊富
- **スケーラブル**: Lambdaがサーバーレスでスケール
- **コスト効率**: リクエスト数に応じた従量課金

---

# API Gateway 制御機能比較

## スロットリング (Throttling)

### 概要
- **対象**: API Gatewayのステージ全体 / メソッド単位
- **内容**: APIリクエストの速度制御（Rate Limit）
- **例**: 「1秒あたり100リクエストまで」
- **使いどころ**: API全体での負荷制御・スパイク対策
- **特徴**: 誰が使っても同じ制限が適用される（グローバル制御）

## 使用量プラン (Usage Plan)

### 概要
- **対象**: API Gateway + APIキーを持つクライアントごと
- **内容**: クライアントごとに制御（Quota / Throttling）
- **クォータ**: 例「1日10,000リクエストまで」
- **スロットリング**: 例「このキーは1秒あたり10リクエストまで」
- **使いどころ**: マルチテナント（サードパーティや顧客ごと）に利用制御
- **前提条件**: APIキー必須
- **特徴**: 個別ユーザーごとの制御

## 制御方式の違い

### スロットリングのみ
- 「このAPIは全体で1秒あたり100リクエストまで」
- 全員で共有 → 誰かが使いすぎたら他の人も影響を受ける

### 使用量プラン
- Vendor A → 1日10,000回まで、1秒あたり10リクエスト
- Vendor B → 1日5,000回まで、1秒あたり5リクエスト
- ベンダーごとに制御可能

## 実践例

### 全体制御（スロットリング）
API全体で「1秒あたり500リクエストまで」

### 顧客別制御（使用量プラン）
- 顧客A（大口）: 1日100,000リクエストまで、1秒あたり50リクエスト
- 顧客B（中小）: 1日10,000リクエストまで、1秒あたり5リクエスト
- 顧客C（無料プラン）: 1日1,000リクエストまで、1秒あたり2リクエスト

---

# Compute Savings Plans

## 概要
AWSの コスト最適化サービス の一つで、特に EC2 / Fargate / Lambda の料金を安くする仕組み

## Savings Plansとの違い

### Compute Savings Plans
- 一番柔軟
- EC2、Fargate、Lambda 全部で使用可能
- インスタンスタイプ / OS / リージョンに縛られない

### EC2 Instance Savings Plans
- 特定のインスタンスタイプ（例: m5.large、リージョン: ap-northeast-1）に縛られる
- その代わり Compute よりさらに割引率が高い